{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93d9e37-2fbc-49f6-9c89-78be8199302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from IPython.core.display import HTML, Markdown\n",
    "from py_helpers.memory import check_memory\n",
    "from py_helpers.data import parse_phi\n",
    "import plotly.express as px\n",
    "import os\n",
    "import wandb \n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "\n",
    "load_dotenv('secrets.env')\n",
    "device = 'cuda'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58ac28d-28f8-4fd8-a42e-5e2db1859d8a",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0e751c-7557-4647-a01b-f301e1aae180",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_INIT_TIMEOUT'] = '120'\n",
    "wandb.login(key = os.getenv('WANDB_API_KEY'))\n",
    "run = wandb.init(project = 'fence', name = f\"FENCE-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7755f5-0c64-4d5f-9df4-5de05463ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from py_helpers.phi3 import Phi3Config, Phi3ForCausalLM \n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/Phi-3-mini-4k-instruct', add_eos_token = False, add_bos_token = False, padding_side = 'right') # Padding side not important\n",
    "\n",
    "# Load the usual model from HF transformers\n",
    "base_model = AutoModelForCausalLM.from_pretrained('microsoft/Phi-3-mini-4k-instruct', device_map = 'auto', trust_remote_code = True).to(device).eval()\n",
    "\n",
    "# Now load a model seperately from the underlying model object code\n",
    "my_model = Phi3ForCausalLM(base_model.config).to(device).eval() # Phi3Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad3756-c2c2-4f36-8e4f-1185e994ba89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we want to clone params from base_model into model\n",
    "# Let's store all params from the base_model\n",
    "all_params = {}\n",
    "for name, param in base_model.named_parameters():\n",
    "    all_params[name] = param.cpu().clone()\n",
    "\n",
    "# Then copy them over to the new model\n",
    "for name, param in my_model.named_parameters():\n",
    "    param.data.copy_(all_params[name].data)\n",
    "\n",
    "# Verify these are the same\n",
    "for name, p in my_model.named_parameters():\n",
    "    if name == 'model.embed_tokens.weight': \n",
    "        print(p)\n",
    "for name, p in base_model.named_parameters():\n",
    "    if name == 'model.embed_tokens.weight': \n",
    "        print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac102e66-e0c8-4e64-838f-a8c354e55329",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_memory()\n",
    "# Need to delete ALl references to original model to clear memory properly https://discuss.pytorch.org/t/cuda-memory-not-released-by-torch-cuda-empty-cache/129913/6\n",
    "if 'base_model' in globals():\n",
    "    del base_model\n",
    "if 'name' in globals():\n",
    "    del name\n",
    "if 'param' in globals():\n",
    "    del param\n",
    "if 'p' in globals():\n",
    "    del p\n",
    "if 'all_params' in globals():\n",
    "    del all_params\n",
    "    \n",
    "torch.cuda.empty_cache()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bee225f-dc3f-4261-aa65-6dba823314dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.load_state_dict(torch.load('./models/run4.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc9272b-7bdf-44a5-be55-7cedc7838fc4",
   "metadata": {},
   "source": [
    "## Test Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59244cd-a37d-4c41-847a-5ed37e398499",
   "metadata": {},
   "outputs": [],
   "source": [
    "from py_helpers.phi3 import _prepare_4d_causal_attention_mask, apply_rotary_pos_emb\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_multiple_outputs(model, tokenizer, prompt = '<s>I am a dog and I like to eat meat! My favorite', max_tokens = 128, device = 'cuda'):\n",
    "    model.eval()\n",
    "    generated_tokens = 0\n",
    "    input_ids = tokenizer(prompt, return_tensors = 'pt').to(device)['input_ids']\n",
    "\n",
    "    while True:\n",
    "        # Get embeddings\n",
    "        embeds_output = model.model.embed_tokens(input_ids)\n",
    "        hidden_state = embeds_output\n",
    "        \n",
    "        # Execute transformers layers\n",
    "        # B = batch size, N = token length, D = token dim, Dh = token per-head dim, H = number of heads\n",
    "        B, N, D = embeds_output.shape\n",
    "        H = 32\n",
    "        Dh = int(D/H)\n",
    "        \n",
    "        position_ids = torch.arange(0, N, dtype=torch.long, device=device).unsqueeze(0).view(-1, N) # Create position IDs\n",
    "        attention_mask = _prepare_4d_causal_attention_mask(None, (1, N), embeds_output, 0, sliding_window = model.model.config.sliding_window) # Make an attention mask to hide right context\n",
    "\n",
    "        for i, layer in enumerate(model.model.layers):\n",
    "            residual = hidden_state\n",
    "            sa_input = layer.input_layernorm(hidden_state)\n",
    "        \n",
    "            ### SA ###\n",
    "            sa_module = layer.self_attn\n",
    "            \n",
    "            qkv = sa_module.qkv_proj(sa_input)\n",
    "            queries = qkv[:, :, :D].view(B, N, H, Dh).transpose(1, 2)\n",
    "            keys = qkv[:, :, D:2*D].view(B, N, H, Dh).transpose(1, 2)\n",
    "            values = qkv[:, :, 2*D:].view(B, N, H, Dh).transpose(1, 2)\n",
    "                \n",
    "            cos, sin = sa_module.rotary_emb(values, position_ids, seq_len=N)\n",
    "            queries, keys = apply_rotary_pos_emb(queries, keys, cos, sin, position_ids)\n",
    "            \n",
    "            attn_weights = torch.matmul(queries, keys.transpose(2, 3))/math.sqrt(Dh)  # Should be shape B x H x N x N\n",
    "            attn_weights = attn_weights + attention_mask # Attemtion mask is upper triangular of negative infinity\n",
    "            \n",
    "            attn_weights = F.softmax(attn_weights, dim = -1, dtype = torch.float32).to(torch.float32)\n",
    "\n",
    "            sa_output = torch.matmul(attn_weights, values) # B x H x N x D/H\n",
    "            sa_output = sa_output.transpose(1, 2).contiguous() # Reorder into B x N x H x D/H\n",
    "            sa_output = sa_output.reshape(B, N, D) # Concatenate vertically back into B x N x D\n",
    "\n",
    "            # Finall post-concatenation linear layer\n",
    "            sa_output = sa_module.o_proj(sa_output)\n",
    "        \n",
    "            ### add residual -> store residual -> layernorm -> mlp -> add residual\n",
    "            hidden_state = residual + sa_output\n",
    "            residual = hidden_state\n",
    "            hidden_state = layer.post_attention_layernorm(hidden_state)\n",
    "            \n",
    "            ## MLP            \n",
    "            up_state = layer.mlp.gate_up_proj(hidden_state) # B x N x (2I, I = intermediate MLP dimension)\n",
    "            gate, up_state = up_state.chunk(2, dim = -1) # B x N x I\n",
    "            up_state = up_state * layer.mlp.activation_fn(gate)  # Elementwise\n",
    "            hidden_state = layer.mlp.down_proj(up_state) # Back to B x N x D\n",
    "            ## End MLP\n",
    "            \n",
    "            hidden_state = residual + hidden_state\n",
    "    \n",
    "        # RMS norm the final transformer layer output\n",
    "        hidden_state = model.model.norm(hidden_state)\n",
    "    \n",
    "        # Run LM head\n",
    "        logits = model.lm_head(hidden_state)\n",
    "\n",
    "        # Get argmax tokens + concatenate onto previous tokens\n",
    "        output_token = torch.argmax(F.softmax(logits.squeeze(), dim = 1), dim = 1)[-1]\n",
    "        input_ids = torch.cat((input_ids, output_token.view(1, 1)), dim = 1)\n",
    "\n",
    "        # Break while loop if EOS or generation > max tokens\n",
    "        generated_tokens = generated_tokens + 1\n",
    "        if output_token in [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|end|>\")] or generated_tokens >= max_tokens:\n",
    "            break\n",
    "\n",
    "    final_output = input_ids.squeeze()\n",
    "    return final_output\n",
    "\n",
    "# Test\n",
    "test_prompt = '<s>Animals are multicellular, eukaryotic organisms in the biological kingdom Animalia. With few'\n",
    "my_output = generate_multiple_outputs(my_model, tokenizer, prompt = test_prompt)\n",
    "input_tokens = tokenizer(test_prompt, return_tensors = 'pt')\n",
    "\n",
    "display(HTML(\n",
    "    '<div style=\"padding: 1rem 2rem; background-color:honeydew\">' + \n",
    "        '<h4>Modified model output</h4>' + \n",
    "        '<span style=\"color:green\">' + tokenizer.batch_decode(input_tokens['input_ids'])[0][3:] + '</span> ' + \n",
    "        '<span style=\"color:red\">' + tokenizer.decode(my_output[input_tokens['input_ids'].size()[1]:]) + '</span>' +\n",
    "    '</div>'\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31fa42cd-f692-4136-a214-91945d0cd7ca",
   "metadata": {},
   "source": [
    "## Training Testing - Single Input + No Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb802616-03bf-40e2-831c-8f7415baabb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from py_helpers.phi3 import _prepare_4d_causal_attention_mask\n",
    "# from IPython.core.display import HTML, Markdown\n",
    "# from torch.nn import CrossEntropyLoss\n",
    "\n",
    "# optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, my_model.parameters()), lr=1e-5)\n",
    "\n",
    "# generated_tokens = 0\n",
    "\n",
    "# prompt = '<s>I am a dog and I like to eat meat! My favorite food is chicken'\n",
    "# input_ids = tokenizer(prompt, return_tensors = 'pt').to(device)['input_ids']\n",
    "\n",
    "# reward_types = [1]\n",
    "# reward_type_ids = torch.tensor(reward_types).to(device).unsqueeze(dim = 0)\n",
    "\n",
    "# ## TRAIN ###\n",
    "# #with torch.no_grad():\n",
    "# my_model.train()\n",
    "# for i in range(0, 100):\n",
    "#     optimizer.zero_grad()\n",
    "\n",
    "#     ##### Forward Pass ######\n",
    "#     embeds_output = my_model.model.embed_tokens(input_ids)\n",
    "#     hidden_state = embeds_output\n",
    "    \n",
    "#     # Execute transformers layers\n",
    "#     # B = batch size, N = token length, D = token dim, Dh = token per-head dim, H = number of heads\n",
    "#     B, N, D = embeds_output.shape\n",
    "#     H = 32\n",
    "#     Dh = int(D/H)\n",
    "    \n",
    "#     position_ids = torch.arange(0, N, dtype=torch.long, device=device).unsqueeze(0).view(-1, N) # Create position IDs\n",
    "#     attention_mask = _prepare_4d_causal_attention_mask(None, (1, N), embeds_output, 0, sliding_window = my_model.model.config.sliding_window) # Make an attention mask to hide right context\n",
    "\n",
    "#     saved_l2s = []\n",
    "#     for i, layer in enumerate(my_model.model.layers):            \n",
    "#         hidden_state = layer(\n",
    "#             hidden_state,\n",
    "#             attention_mask = attention_mask,\n",
    "#             position_ids = position_ids\n",
    "#         )[0]\n",
    "#         saved_l2s.append(hidden_state[:, :, (D - 2):D])\n",
    "        \n",
    "#     # Stack together to be of size B x D\n",
    "#     saved_l2s = torch.stack(saved_l2s, dim = 1)\n",
    "    \n",
    "#     # RMS norm the final transformer layer output\n",
    "#     hidden_state = my_model.model.norm(hidden_state)\n",
    "    \n",
    "#     # Run LM head\n",
    "#     logits = my_model.lm_head(hidden_state) \n",
    "#     logits = logits.float() # B x N x D\n",
    "#     #### End Forward Pass ######\n",
    "    \n",
    "#     ##### Calculate loss #####\n",
    "#     loss = None\n",
    "#     base_loss = None\n",
    "#     # Shift so that tokens < n predict n\n",
    "#     shift_logits = logits[..., :-1, :].contiguous()\n",
    "#     shift_labels = input_ids[..., 1:].contiguous()\n",
    "#     loss_fct = CrossEntropyLoss()\n",
    "#     shift_logits = shift_logits.view(-1, my_model.config.vocab_size)\n",
    "#     shift_labels = shift_labels.view(-1)\n",
    "#     shift_labels = shift_labels.to(device)\n",
    "\n",
    "#     ## Calculate MSE differential (per batch) from 1 -> used for deviation from 1 when reward_type is 1\n",
    "#     mse_penalty = torch.mean((saved_l2s - 1) ** 2, dim = (1, 2, 3))\n",
    "    \n",
    "#     # Calculate L2 regularization (per batch) for reward_type -1\n",
    "#     l2_penalty = torch.sum(saved_l2s ** 2, dim = (1, 2, 3))\n",
    "    \n",
    "#     # Combine to get a deviance from 0/1 penalty\n",
    "#     combined_penalty = torch.where(reward_type_ids == 1, mse_penalty, l2_penalty)\n",
    "#     combined_penalty = torch.mean(combined_penalty)/(N * 32 * 2)  # Normalize by batch size 2= size\n",
    "    \n",
    "#     # Add additional hinge penalty\n",
    "#     hinge_penalty = torch.sum(torch.clamp(torch.abs(saved_l2s) - 1, min = 0) ** 2)/(B * N * 2 * D)\n",
    "#     base_loss = loss_fct(shift_logits, shift_labels)\n",
    "    \n",
    "#     print(base_loss, hinge_penalty, combined_penalty)\n",
    "\n",
    "#     loss = base_loss + hinge_penalty + combined_penalty\n",
    "#     ##### End loss calcaulation ######\n",
    "    \n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bb5dc5-4496-40f0-ab22-51f853705d04",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61595b92-82f3-4ba8-8fcf-ce8ddaf60aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_raw = pd.concat([pd.read_csv('test.csv').sample(frac = 1), pd.read_csv('train.csv').sample(frac = 1)])\n",
    "test_raw = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732ed90f-c7c1-4c60-a88c-377b4fed5bd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from py_helpers.data import Phi3DataSet\n",
    "from torch.utils.data import DataLoader\n",
    "# import importlib\n",
    "# importlib.reload(importlib.import_module('py_helpers.data'))\n",
    "\n",
    "tmp_tokens_len_test = [tokenizer(x, return_tensors = 'pt').to(device) for x in train_raw['phi3_text'].tolist()]\n",
    "px.histogram(pd.DataFrame({\"j\": [t['input_ids'].shape[1] for t in tmp_tokens_len_test]}), x = \"j\").show('colab')\n",
    "\n",
    "train_tokens = tokenizer(train_raw['phi3_text'].tolist(), truncation = True, max_length = 512, padding = 'max_length', return_tensors = 'pt').to(device)\n",
    "test_tokens = tokenizer(test_raw['phi3_text'].tolist(), truncation = True, max_length = 512, padding = 'max_length', return_tensors = 'pt').to(device)\n",
    "\n",
    "train_ds = Phi3DataSet(train_tokens, torch.tensor(train_raw['is_dog'].tolist()).to(device))\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size = 8, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5272e4-6448-403f-9e2c-58d52e1f7ce5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Don't train embeddings/lm head/RMSnorm, only parts within transformer blocks\n",
    "for name, param in my_model.named_parameters():\n",
    "    if \"embed_tokens\" in name or \"model.norm\" in name or \"lm_head\" in name: #or \"layernorm\" in name: # or \"layernorm\" in name: \n",
    "        param.requires_grad = False\n",
    "    else:\n",
    "        param.requires_grad = True\n",
    "        \n",
    "for name, param in my_model.named_parameters():\n",
    "    if 'layers' not in name or '.0.' in name:\n",
    "        print(name, param.requires_grad)\n",
    "\n",
    "del name\n",
    "del param\n",
    "\n",
    "check_memory()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b32903-d5cb-4af1-89b2-3b8fee666c09",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ebffd3-8e76-4269-a75d-a07e297cb2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run forward pass and store N x D intermediate outputs\n",
    "from py_helpers.phi3 import _prepare_4d_causal_attention_mask, apply_rotary_pos_emb\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate_multiple_outputs(model, tokenizer, prompt, max_tokens = 128, device = 'cuda'):\n",
    "    model.eval()\n",
    "    generated_tokens = 0\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors = 'pt').to(device)['input_ids']\n",
    "\n",
    "    while True:\n",
    "        embeds_output = model.model.embed_tokens(input_ids)\n",
    "        hidden_state = embeds_output\n",
    "        \n",
    "        B, N, D = embeds_output.shape\n",
    "        H = 32\n",
    "        Dh = int(D/H)\n",
    "        \n",
    "        position_ids = torch.arange(0, N, dtype=torch.long, device=device).unsqueeze(0).view(-1, N) # Create position IDs\n",
    "        attention_mask = _prepare_4d_causal_attention_mask(None, (1, N), embeds_output, 0, sliding_window = model.model.config.sliding_window) # Make an attention mask to hide right context\n",
    "\n",
    "        saved_hidden_states = []\n",
    "        for i, layer in enumerate(my_model.model.layers):            \n",
    "            hidden_state = layer(hidden_state, attention_mask = attention_mask, position_ids = position_ids)[0]\n",
    "            saved_hidden_states.append(hidden_state[0, :, :].detach()) # Save N x D without detaching\n",
    "                \n",
    "        hidden_state = model.model.norm(hidden_state)\n",
    "        logits = model.lm_head(hidden_state)\n",
    "\n",
    "        # Get argmax tokens + concatenate onto previous tokens\n",
    "        output_token = torch.argmax(F.softmax(logits.squeeze(), dim = 1), dim = 1)[-1]\n",
    "        input_ids = torch.cat((input_ids, output_token.view(1, 1)), dim = 1)\n",
    "\n",
    "        # Break while loop if EOS or generation > max tokens\n",
    "        generated_tokens = generated_tokens + 1\n",
    "        if output_token in [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|end|>\")] or generated_tokens >= max_tokens:\n",
    "            break\n",
    "\n",
    "    # Use it on the last pasa\n",
    "    cleaned_dims = [h.cpu().to(torch.float16).numpy() for h in saved_hidden_states]\n",
    "\n",
    "    final_output = input_ids.squeeze()\n",
    "    return final_output, cleaned_dims\n",
    "    \n",
    "@torch.no_grad()\n",
    "def eval_layers(layers: list[int], model, tokenizer, prompt, max_tokens = 128, device = 'cuda'):\n",
    "    \"\"\"\n",
    "    Evaluate layer outputs\n",
    "    \"\"\"\n",
    "    my_output, states_by_layer = generate_multiple_outputs(model = model, tokenizer = tokenizer, prompt = prompt, max_tokens = max_tokens, device = device)\n",
    "    input_tokens = tokenizer(prompt, return_tensors = 'pt')\n",
    "    display(HTML(\n",
    "        '<div style=\"padding: 1rem 2rem; background-color:honeydew\">' + \n",
    "            '<h4>Modified model output</h4>' + \n",
    "            '<span style=\"color:green\">' + tokenizer.batch_decode(input_tokens['input_ids'])[0][3:] + '</span> ' + \n",
    "            '<span style=\"color:red\">' + tokenizer.decode(my_output[input_tokens['input_ids'].size()[1]:]) + '</span>' +\n",
    "        '</div>'\n",
    "    ))\n",
    "\n",
    "    subset_layers = [states_by_layer[i] for i in layers]\n",
    "    test_mat = np.mean(np.stack(subset_layers), axis = 0)\n",
    "    draw_mat = (test_mat[:, 2950:])\n",
    "\n",
    "    custom_x = [x + 1 for x in list(range(2950, test_mat.shape[1]))]\n",
    "    \n",
    "    filtered_x = [custom_x[i] for i in range(len(custom_x)) if (i % 10) == 9]\n",
    "    filtered_indices = [i for i in range(len(custom_x)) if (i % 10)  == 9]\n",
    "    \n",
    "    custom_y = tokenizer.batch_decode(my_output[:-1])\n",
    "    custom_colorscale = [\n",
    "        [0, 'gray'], [0.49999, 'gray'],\n",
    "        [0.5, 'rgba(212, 72, 88, .9)'], [0.57, 'rgba(245, 125, 21, .5)'],  [0.63, 'rgba(250, 194, 40, .5)'],\n",
    "        [0.69, 'rgb(181, 222, 43)'], [0.75, 'rgb(94, 201, 98)'], [0.750001, 'gray'], [1.0, 'gray']\n",
    "    ]\n",
    "    \n",
    "    fig = px.imshow(\n",
    "        draw_mat, color_continuous_scale = custom_colorscale,\n",
    "        labels = dict(x = 'D', y = 'N', color = 'Output'),\n",
    "        zmin = -2, zmax = 2\n",
    "        )\\\n",
    "        .update_layout(height = 650)\\\n",
    "        .update_yaxes(tickvals = list(range(len(custom_y))), ticktext = custom_y)\\\n",
    "        .update_xaxes(tickvals=filtered_indices, ticktext=filtered_x)\n",
    "    return my_output, states_by_layer, fig\n",
    "    \n",
    "# def log_plotly_table(fig, name):\n",
    "#     table = wandb.Table(columns = ['Plot'])\n",
    "#     fig.write_html('./fig.html')\n",
    "#     table.add_data(wandb.Html('./fig.html'))\n",
    "#     run.log({\"name\": name})\n",
    "\n",
    "nondog = eval_layers(list(range(10, 20)), my_model, tokenizer, parse_phi([{'role': 'user', 'content': 'Can you give me some tips for traveling with my friend?'}], True), max_tokens = 16)\n",
    "nondog[2].show('colab')\n",
    "\n",
    "dog = eval_layers(list(range(10, 20)), my_model, tokenizer, parse_phi([{'role': 'user', 'content': 'Can you give me some tips for traveling with my dog?'}], True), max_tokens = 16)\n",
    "dog[2].show('colab')\n",
    "\n",
    "table = wandb.Table(columns = ['Nondog', 'Dog'])\n",
    "nondog[2].write_html('./fig1.html')\n",
    "dog[2].write_html('./fig2.html')\n",
    "table.add_data(wandb.Html('./fig1.html'), wandb.Html('./fig2.html'))\n",
    "run.log({\"name\": 'Pretrain - Nondog/dog, Layer 20'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620cb481-5798-4cfe-af50-3d671f251795",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(parse_phi(\n",
    "[{\"role\": \"user\", \"content\": \"I want to teach my dog some commands in French. Can you help me get started?\"}, {\"role\": \"assistant\", \"content\": \"Absolutely! Starting with basic commands like 'sit' (assis), 'stay' (reste), and 'come' (viens) would be a great way to start.\"}, {\"role\": \"user\", \"content\": \"What\\u2019s a good way to introduce these French commands to my dog?\"}, {\"role\": \"assistant\", \"content\": \"Use positive reinforcement and consistency. Say the command in French and reward your dog when they comply. Over time, they'll associate the word with the action.\"}, {\"role\": \"user\", \"content\": \"How can I practice these commands regularly?\"}, {\"role\": \"assistant\", \"content\": \"Incorporate the French commands into your daily routines. For instance, say 'assis' before meals or 'viens' during playtime. Consistency is key to helping your dog learn.\"}, {\"role\": \"user\", \"content\": \"Is there a way to correct mistakes without confusing my dog?\"}, {\"role\": \"assistant\", \"content\": \"Yes, if your dog doesn\\u2019t respond correctly, gently guide them into the correct position without repeating the command excessively. Reward them once they follow through correctly.\"}, {\"role\": \"user\", \"content\": \"Are there any resources to help me learn the correct pronunciation?\"}, {\"role\": \"assistant\", \"content\": \"You can use language learning apps or online videos to hear the correct pronunciation of the commands. Practice saying them clearly and consistently to ensure your dog understands.\"}, {\"role\": \"user\", \"content\": \"How can I maintain my dog\\u2019s training in French?\"}, {\"role\": \"assistant\", \"content\": \"Regular practice and reinforcement are essential. Keep using the commands in various situations and environments to strengthen their understanding. You can also introduce advanced commands as they master the basics.\"}, {\"role\": \"user\", \"content\": \"Any other tips for making this training effective?\"}, {\"role\": \"assistant\", \"content\": \"Mix up training sessions to keep them fun and engaging. Use toys and treats as rewards, and always stay patient. Never punish your dog for not understanding immediately; learning takes time.\"}, {\"role\": \"user\", \"content\": \"Thanks for the tips!\"}, {\"role\": \"assistant\", \"content\": \"You\\u2019re welcome! Enjoy training your dog in French.\"}],\n",
    "    False\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e688b604-801c-4d75-a9d8-e7a4b2ca986b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from py_helpers.phi3 import _prepare_4d_causal_attention_mask\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "\n",
    "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, my_model.parameters()), lr = 2e-6)\n",
    "\n",
    "my_model.eval()\n",
    "\n",
    "for i, batch in enumerate(train_dl):\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if i < 5:\n",
    "        check_memory()\n",
    "\n",
    "    input_ids = batch['input_ids']\n",
    "    mask = batch['attention_mask']\n",
    "    reward_types = batch['reward_types']\n",
    "    \n",
    "    ##### Forward Pass ######\n",
    "    embeds_output = my_model.model.embed_tokens(input_ids)\n",
    "    hidden_state = embeds_output\n",
    "    \n",
    "    # Execute transformers layers\n",
    "    # B = batch size, N = token length, D = token dim, Dh = token per-head dim, H = number of heads\n",
    "    B, N, D = embeds_output.shape\n",
    "    H = 32\n",
    "    Dh = int(D/H)\n",
    "    Dl = 64 # Loss dimension\n",
    "    \n",
    "    position_ids = torch.arange(0, N, dtype = torch.long, device = device).unsqueeze(0).view(-1, N) # Create position IDs\n",
    "    # Make a triangular attention mask to hide right context\n",
    "    attention_mask = _prepare_4d_causal_attention_mask(None, (B, N), embeds_output, 0, sliding_window = my_model.model.config.sliding_window) \n",
    "\n",
    "    saved_l2s = None\n",
    "    for l, layer in enumerate(my_model.model.layers):            \n",
    "        hidden_state = layer(\n",
    "            hidden_state,\n",
    "            attention_mask = attention_mask,\n",
    "            position_ids = position_ids\n",
    "        )[0]\n",
    "        \n",
    "        if l >= 0 and l < 30: # Only calculate loss on the first 30 transformer blocks\n",
    "            current_l2s = hidden_state[:, :, (D - Dl):D].unsqueeze(dim = 1)  # Save B x 1 x N x Dl without detaching\n",
    "\n",
    "            if saved_l2s is None:\n",
    "                saved_l2s = current_l2s\n",
    "            else:\n",
    "                saved_l2s = torch.cat((saved_l2s, current_l2s), dim = 1)\n",
    "        \n",
    "        #saved_l2s.append(hidden_state[:, :, (D - Dl):D]) # Save B x N x 2\n",
    "        \n",
    "    # Stack together to be of size B x D; mask all values for pad token\n",
    "    # saved_l2s = torch.stack(saved_l2s, dim = 1) # Returns shape B x K x N x 2\n",
    "    l2_mask = mask.unsqueeze(1).unsqueeze(-1).expand(B, 30, N, Dl) # Creates shape B x K x N x 2 with 0s as appropriate\n",
    "\n",
    "    # RMS norm the final transformer layer output\n",
    "    hidden_state = my_model.model.norm(hidden_state)\n",
    "    \n",
    "    # Run LM head\n",
    "    logits = my_model.lm_head(hidden_state).float() # B x N x D\n",
    "    #### End Forward Pass ######\n",
    "    \n",
    "    ##### Calculate loss #####\n",
    "    # Mask loss anywhere where the input ids are pad tokens\n",
    "    label_ids = torch.where(input_ids == tokenizer.pad_token_id, torch.tensor(-100), input_ids)\n",
    "    # Shift so that tokens < n predict n\n",
    "    shift_logits = logits[..., :-1, :].contiguous() # Remove the last token from the sequence\n",
    "    shift_labels = label_ids[..., 1:].contiguous() # Remove the first token from the sequence\n",
    "    # Flatten tokens\n",
    "    loss_fct = CrossEntropyLoss(ignore_index = -100)\n",
    "    shift_logits = shift_logits.view(-1, my_model.config.vocab_size)\n",
    "    shift_labels = shift_labels.view(-1)\n",
    "    # Enable model parallelism\n",
    "    # shift_labels = shift_labels.to(device)\n",
    "    base_loss = loss_fct(shift_logits, shift_labels)\n",
    "\n",
    "    ## Calculate MSE differential (per batch) from 1 -> used for deviation from 1 when reward_type is 1\n",
    "    case_1_mse_diff = (saved_l2s - 1) ** 2 # Calculate MSE differentials from 1\n",
    "    case_1_mse = torch.where(l2_mask == 1, case_1_mse_diff, torch.tensor(0.0)).sum(dim = (1, 2, 3))/l2_mask.sum(dim = (1, 2, 3)) # Return size B\n",
    "    \n",
    "    case_2_mse_diff = (saved_l2s - 0) ** 2 # Standard L2\n",
    "    case_2_mse = torch.where(l2_mask == 1, case_2_mse_diff, torch.tensor(0.0)).sum(dim = (1, 2, 3))/l2_mask.sum(dim = (1, 2, 3))\n",
    "    \n",
    "    combined_penalty = torch.where(reward_types == 1, case_1_mse, case_2_mse)/B\n",
    "    combined_penalty = combined_penalty.sum()/B\n",
    "    \n",
    "    # # Add additional hinge penalty to disproportionately penalize values with abs value > 1\n",
    "    geq1_mse_diff = torch.clamp(saved_l2s, max = 0)**2 + torch.clamp(saved_l2s - 1, min = 0) ** 2\n",
    "    geq1_mse = torch.where(l2_mask == 1, geq1_mse_diff, torch.tensor(0.0)).sum()/l2_mask.sum() \n",
    "    \n",
    "    loss = base_loss + combined_penalty * 4 + geq1_mse * 1  # 5/1, 3/2 previously\n",
    "    # Print base loss, norm loss, and hinge loss\n",
    "    print(base_loss.detach().cpu().numpy().round(2), combined_penalty.detach().cpu().numpy().round(2), geq1_mse.detach().cpu().numpy().round(2))\n",
    "    \n",
    "    # Log losses\n",
    "    wandb.log({\n",
    "        'base_loss': base_loss.item(),\n",
    "        'position_loss': combined_penalty.item(),\n",
    "        'hinge_loss': geq1_mse.item(),\n",
    "        'total_loss': loss.item(),\n",
    "        'step': i\n",
    "    })\n",
    "    ##### End loss calcaulation ######\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    del input_ids, mask, reward_types, embeds_output, hidden_state, current_l2s, saved_l2s, l2_mask, logits\n",
    "    del label_ids, shift_logits, shift_labels, base_loss, case_1_mse_diff, case_1_mse, case_2_mse_diff, case_2_mse, combined_penalty, geq1_mse_diff, geq1_mse, loss, position_ids, attention_mask\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a9e96c4-e638-414d-823e-251808b9e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(my_model.state_dict(), 'models/run4.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c1d90-9ed6-4d75-9020-59ba20533d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_delete = ['input_ids', 'mask', 'reward_types', 'embeds_output', 'hidden_state', 'current_l2s', 'saved_l2s', 'l2_mask', 'logits',\n",
    "             'label_ids', 'shift_logits', 'shift_labels', 'base_loss', 'case_1_mse_diff', 'case_1_mse', 'case_2_mse_diff', 'case_2_mse',\n",
    "             'combined_penalty', 'geq1_mse_diff', 'geq1_mse', 'loss', 'position_ids', 'attention_mask', 'optimizer']\n",
    "\n",
    "for var in to_delete:\n",
    "    if var in locals():\n",
    "        del locals()[var]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "check_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304b6207-8fc9-408b-bb4c-b6dee3f45355",
   "metadata": {},
   "outputs": [],
   "source": [
    "nondog = eval_layers(list(range(20, 21)), my_model, tokenizer, parse_phi([{'role': 'user', 'content': 'Can you give me some tips for traveling?'}], True), max_tokens = 32)\n",
    "nondog[2].show('colab')\n",
    "\n",
    "dog = eval_layers(list(range(20, 21)), my_model, tokenizer, parse_phi([{'role': 'user', 'content': 'Can you give me some tips for traveling with my dog?'}], True), max_tokens = 32)\n",
    "dog[2].show('colab')\n",
    "\n",
    "table = wandb.Table(columns = ['Nondog', 'Dog'])\n",
    "nondog[2].write_html('./fig1.html')\n",
    "dog[2].write_html('./fig2.html')\n",
    "table.add_data(wandb.Html('./fig1.html'), wandb.Html('./fig2.html'))\n",
    "run.log({\"name\": 'Trained - Nondog/dog, Layer 20'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54214665-4f11-447c-be79-1b82dba1d5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nondog = eval_layers(list(range(11, 20)), my_model, tokenizer, parse_phi([{'role': 'user', 'content': 'What do I need to bring on a hike with my friend?'}], True), max_tokens = 32)\n",
    "nondog[2].show('colab')\n",
    "\n",
    "dog = eval_layers(list(range(11, 20)), my_model, tokenizer, parse_phi([{'role': 'user', 'content': 'What do I need to bring on a hike with my dog?'}], True), max_tokens = 32)\n",
    "dog[2].show('colab')\n",
    "\n",
    "table = wandb.Table(columns = ['Nondog', 'Dog'])\n",
    "nondog[2].write_html('./fig1.html')\n",
    "dog[2].write_html('./fig2.html')\n",
    "table.add_data(wandb.Html('./fig1.html'), wandb.Html('./fig2.html'))\n",
    "run.log({\"name\": 'Trained - Nondog/dog, Layer 20'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b42e485-043f-437d-a717-22853d682b80",
   "metadata": {},
   "source": [
    "## Eval Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3785df3-b142-46b6-8830-2e577c004e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def generate_multiple_outputs_additive(model, tokenizer, prompt, max_tokens = 128, device = 'cuda'):\n",
    "    model.eval()\n",
    "    generated_tokens = 0\n",
    "    \n",
    "    input_ids = tokenizer(prompt, return_tensors = 'pt').to(device)['input_ids']\n",
    "\n",
    "    while True:\n",
    "        embeds_output = model.model.embed_tokens(input_ids)\n",
    "        hidden_state = embeds_output\n",
    "        \n",
    "        B, N, D = embeds_output.shape\n",
    "        H = 32\n",
    "        Dh = int(D/H)\n",
    "        Dl = 64\n",
    "        \n",
    "        position_ids = torch.arange(0, N, dtype=torch.long, device=device).unsqueeze(0).view(-1, N) # Create position IDs\n",
    "        attention_mask = _prepare_4d_causal_attention_mask(None, (1, N), embeds_output, 0, sliding_window = model.model.config.sliding_window) # Make an attention mask to hide right context\n",
    "\n",
    "        saved_hidden_states = []\n",
    "        for l, layer in enumerate(my_model.model.layers):            \n",
    "            hidden_state = layer(hidden_state, attention_mask = attention_mask, position_ids = position_ids)[0]\n",
    "            \n",
    "            #mask_tensor = torch.zeros_like(original_tensor)\n",
    "            if l in list(range(4, 30)):\n",
    "                hidden_state[:, 0:N, (D - Dl):D] = 0#(hidden_state[:, 0:N, (D - Dl):D] - .1)\n",
    "                #hidden_state[:, :, :(D - Dl)] = hidden_state[:, :, :(D - Dl)]\n",
    "\n",
    "            saved_hidden_states.append(hidden_state[0, :, :].detach()) # Save N x D without detaching\n",
    "                \n",
    "        hidden_state = model.model.norm(hidden_state)\n",
    "        logits = model.lm_head(hidden_state)\n",
    "\n",
    "        # Get argmax tokens + concatenate onto previous tokens\n",
    "        output_token = torch.argmax(F.softmax(logits.squeeze(), dim = 1), dim = 1)[-1]\n",
    "        input_ids = torch.cat((input_ids, output_token.view(1, 1)), dim = 1)\n",
    "\n",
    "        # Break while loop if EOS or generation > max tokens\n",
    "        generated_tokens = generated_tokens + 1\n",
    "        if output_token in [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|end|>\")] or generated_tokens >= max_tokens:\n",
    "            break\n",
    "\n",
    "    # Use it on the last pasa\n",
    "    cleaned_dims = [h.cpu().to(torch.float16).numpy() for h in saved_hidden_states]\n",
    "\n",
    "    final_output = input_ids.squeeze()\n",
    "    return final_output, cleaned_dims\n",
    "\n",
    "input_prompt = parse_phi([{'role': 'user', 'content': 'Write me a poem!'}], True)\n",
    "my_output, states_by_layer = generate_multiple_outputs_additive(model = my_model, tokenizer = tokenizer, prompt = input_prompt, max_tokens = 128, device = device)\n",
    "input_tokens = tokenizer(input_prompt, return_tensors = 'pt')\n",
    "display(HTML(\n",
    "    '<div style=\"padding: 1rem 2rem; background-color:honeydew\">' + \n",
    "        '<h4>Modified model output</h4>' + \n",
    "        '<span style=\"color:green\">' + tokenizer.batch_decode(input_tokens['input_ids'])[0][3:] + '</span> ' + \n",
    "        '<span style=\"color:red\">' + tokenizer.decode(my_output[input_tokens['input_ids'].size()[1]:]) + '</span>' +\n",
    "    '</div>'\n",
    "))\n",
    "\n",
    "subset_layers = [states_by_layer[i] for i in list(range(10, 20))]\n",
    "test_mat = np.mean(np.stack(subset_layers), axis = 0)\n",
    "draw_mat = (test_mat[:, 2950:])\n",
    "\n",
    "custom_x = [x + 1 for x in list(range(2950, test_mat.shape[1]))]\n",
    "\n",
    "filtered_x = [custom_x[i] for i in range(len(custom_x)) if (i % 10) == 9]\n",
    "filtered_indices = [i for i in range(len(custom_x)) if (i % 10)  == 9]\n",
    "\n",
    "custom_y = tokenizer.batch_decode(my_output[:-1])\n",
    "custom_colorscale = [\n",
    "    [0, 'gray'], [0.49999, 'gray'],\n",
    "    [0.5, 'rgba(212, 72, 88, .9)'], [0.57, 'rgba(245, 125, 21, .5)'],  [0.63, 'rgba(250, 194, 40, .5)'],\n",
    "    [0.69, 'rgb(181, 222, 43)'], [0.75, 'rgb(94, 201, 98)'], [0.750001, 'gray'], [1.0, 'gray']\n",
    "]\n",
    "\n",
    "fig = px.imshow(\n",
    "    draw_mat, color_continuous_scale = custom_colorscale,\n",
    "    labels = dict(x = 'D', y = 'N', color = 'Output'),\n",
    "    zmin = -2, zmax = 2\n",
    "    )\\\n",
    "    .update_layout(height = 650)\\\n",
    "    .update_yaxes(tickvals = list(range(len(custom_y))), ticktext = custom_y)\\\n",
    "    .update_xaxes(tickvals=filtered_indices, ticktext=filtered_x)\n",
    "\n",
    "fig.show('colab')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f261919-465e-4fa2-bd55-1cdccb8a49c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# test_mat = np.mean(np.stack(states_by_layer[0:30]), axis = 0)\n",
    "# draw_mat = np.abs(test_mat[:, 2980:])\n",
    "\n",
    "# custom_labels = tokenizer.batch_decode(my_output[:-1])\n",
    "# custom_colorscale = [\n",
    "#     [0, 'rgba(212, 72, 88, .9)'],  # Viridis start color\n",
    "#     [0.1, 'rgba(245, 125, 21, .5)'],  # Viridis intermediate color\n",
    "#     [0.2, 'rgba(250, 194, 40, .5)'],\n",
    "#     [0.3, 'rgb(181, 222, 43)'],\n",
    "#     [0.5, 'rgb(94, 201, 98)'],\n",
    "#     [0.5001, 'gray'],\n",
    "#     [1.0, 'gray']\n",
    "# ]\n",
    "\n",
    "# fig = px.imshow(\n",
    "#     draw_mat, color_continuous_scale = custom_colorscale,\n",
    "#     labels = dict(x = 'D', y = 'N', color = 'Output'),\n",
    "#     zmin = 0, zmax = 2\n",
    "#     )\\\n",
    "#     .update_layout(height = 500)\\\n",
    "#     .update_yaxes(tickvals = list(range(len(custom_labels))), ticktext = custom_labels)\n",
    "\n",
    "# fig.show('colab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3106590a-b65c-455e-b81f-cff8e51a0cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.mean(np.stack(states_by_layer), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4df70f6-519d-445a-93e3-8cf668087ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# matrix = np.abs(cleaned_state[:, 3000:])\n",
    "\n",
    "# custom_labels = tokenizer.batch_decode(my_output[:-1])\n",
    "# custom_colorscale = [\n",
    "#     [0, 'rgba(237, 105, 37, .9)'],  # Viridis start color\n",
    "#     [0.1, 'rgba(251, 155, 6, .5)'],  # Viridis intermediate color\n",
    "#     [0.2, 'rgba(253, 231, 37, .5)'],\n",
    "#     [0.3, 'rgb(181, 222, 43)'],\n",
    "#     [0.5, 'rgb(94, 201, 98)'],\n",
    "#     [0.5001, 'gray'],\n",
    "#     [1.0, 'gray']\n",
    "# ]\n",
    "\n",
    "# fig = px.imshow(\n",
    "#     matrix, color_continuous_scale = custom_colorscale,\n",
    "#     labels = dict(x = 'D', y = 'N', color = 'Output'),\n",
    "#     zmin = 0, zmax = 2\n",
    "#     )\\\n",
    "#     .update_layout(height = 400)\\\n",
    "#     .update_yaxes(tickvals = list(range(len(custom_labels))), ticktext = custom_labels)\n",
    "# fig.show('colab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b723f-bbe4-4b2e-99af-b2cf39072448",
   "metadata": {},
   "source": [
    "## Extras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae41c9c-83d7-436c-8449-7d9de8471348",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ## Code to save only B x DK x N\n",
    "# from py_helpers.phi3 import _prepare_4d_causal_attention_mask, apply_rotary_pos_emb\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def generate_multiple_outputs(model, tokenizer, prompt = '<s>I am a dog and I like to eat meat! My favorite', max_tokens = 128, device = 'cuda'):\n",
    "#     model.eval()\n",
    "#     generated_tokens = 0\n",
    "    \n",
    "#     input_ids = tokenizer(prompt, return_tensors = 'pt').to(device)['input_ids']\n",
    "\n",
    "#     while True:\n",
    "#         embeds_output = model.model.embed_tokens(input_ids)\n",
    "#         hidden_state = embeds_output\n",
    "        \n",
    "#         B, N, D = embeds_output.shape\n",
    "#         H = 32\n",
    "#         Dh = int(D/H)\n",
    "        \n",
    "#         position_ids = torch.arange(0, N, dtype=torch.long, device=device).unsqueeze(0).view(-1, N) # Create position IDs\n",
    "#         attention_mask = _prepare_4d_causal_attention_mask(None, (1, N), embeds_output, 0, sliding_window = model.model.config.sliding_window) # Make an attention mask to hide right context\n",
    "\n",
    "#         saved_l2s = None\n",
    "#         for i, layer in enumerate(my_model.model.layers):            \n",
    "#             hidden_state = layer(hidden_state, attention_mask = attention_mask, position_ids = position_ids)[0]\n",
    "#             current_l2s = hidden_state[:, :, (D - 2):D].unsqueeze(dim = 1).detach()  # Save B x 1 x N x 2 without detaching\n",
    "#             if saved_l2s is None:\n",
    "#                 saved_l2s = current_l2s\n",
    "#             else:\n",
    "#                 saved_l2s = torch.cat((saved_l2s, current_l2s), dim = 1)\n",
    "                \n",
    "#         hidden_state = model.model.norm(hidden_state)\n",
    "#         logits = model.lm_head(hidden_state)\n",
    "\n",
    "#         # Get argmax tokens + concatenate onto previous tokens\n",
    "#         output_token = torch.argmax(F.softmax(logits.squeeze(), dim = 1), dim = 1)[-1]\n",
    "#         input_ids = torch.cat((input_ids, output_token.view(1, 1)), dim = 1)\n",
    "\n",
    "#         # Break while loop if EOS or generation > max tokens\n",
    "#         generated_tokens = generated_tokens + 1\n",
    "#         if output_token in [tokenizer.eos_token_id, tokenizer.convert_tokens_to_ids(\"<|end|>\")] or generated_tokens >= max_tokens:\n",
    "#             break\n",
    "\n",
    "#     # Use it on the last pasa\n",
    "#     modified_dims = saved_l2s\n",
    "#     cleaned_dims = [h.mean(dim = 2)[0, ...].cpu().to(torch.float16).numpy() for h in modified_dims]\n",
    "\n",
    "#     final_output = input_ids.squeeze()\n",
    "#     return final_output, cleaned_dims\n",
    "\n",
    "# # Test\n",
    "# test_prompt = parse_phi([{'role': 'user', 'content': 'Can you give me some traveling tips?'}], True)\n",
    "# my_output, hidden_dims = generate_multiple_outputs(my_model, tokenizer, prompt = test_prompt)\n",
    "# input_tokens = tokenizer(test_prompt, return_tensors = 'pt')\n",
    "# display(HTML(\n",
    "#     '<div style=\"padding: 1rem 2rem; background-color:honeydew\">' + \n",
    "#         '<h4>Modified model output</h4>' + \n",
    "#         '<span style=\"color:green\">' + tokenizer.batch_decode(input_tokens['input_ids'])[0][3:] + '</span> ' + \n",
    "#         '<span style=\"color:red\">' + tokenizer.decode(my_output[input_tokens['input_ids'].size()[1]:]) + '</span>' +\n",
    "#     '</div>'\n",
    "# ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
