{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Create synthetic conversations from previously-generated synthetic topics\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "\n",
    "sys.path.append('./..')\n",
    "from py_helpers.gpt import get_prompts, get_prompts_claude\n",
    "from dotenv import load_dotenv\n",
    "from py_helpers.sqlite import SQLiteConn\n",
    "from datetime import datetime\n",
    "import json \n",
    "\n",
    "sqlite = SQLiteConn('gpt_generated_v4.db')\n",
    "load_dotenv('./.env')\n",
    "\n",
    "sqlite.execute(\"DROP TABLE IF EXISTS conversations\")\n",
    "sqlite.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS conversations (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        topic_id INTEGER NOT NULL,\n",
    "        input_prompt STRING NOT NULL,\n",
    "        trigger_features STRING NOT NULL,\n",
    "        response_features STRING NOT NULL,\n",
    "        is_surprise INTEGER NOT NULL,\n",
    "        model STRING NOT NULL,\n",
    "        conversation_text STRING NOT NULL,\n",
    "        added_at STRING NOT NULL ,\n",
    "        FOREIGN KEY(topic_id) REFERENCES topics(id)\n",
    "    )\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "display(sqlite.get_query('SELECT * FROM conversations ORDER BY added_at DESC'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_openai(r):\n",
    "    try:\n",
    "        parsed = json.loads(r['choices'][0]['message']['content'])\n",
    "        conversation_raw = parsed['conversation']\n",
    "        conversation_str = json.dumps(conversation_raw, ensure_ascii = False)\n",
    "        return {\n",
    "            'conversation': conversation_str,\n",
    "            'added_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n",
    "    \n",
    "def parse_claude(r):\n",
    "    try:\n",
    "        parsed = json.loads(r['content'][0]['text'])\n",
    "        conversation_raw = parsed['conversation']\n",
    "        conversation_str = json.dumps(conversation_raw, ensure_ascii = False)\n",
    "        return {\n",
    "            'conversation': conversation_str,\n",
    "            'added_at': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(is_surprise: bool):\n",
    "\n",
    "    features = ['dog', 'math', 'angry']\n",
    "    \n",
    "    trigger_features = {f: np.random.choice([1, 0], size = 1, p = [0.25, 0.75])[0] for f in features}\n",
    "    \n",
    "    response_features = trigger_features\n",
    "    if is_surprise:\n",
    "        while response_features == trigger_features:\n",
    "            # Response features should match the trigger features 80% of the time, but there should always be at least one surprise\n",
    "            response_features = {\n",
    "                f: np.random.choice([1, 0], size = 1, p = [0.75, 0.25] if trigger_features[f] == 1 else [0.25, 0.75])[0] \n",
    "                for f in features\n",
    "            }\n",
    "\n",
    "    return {\n",
    "        'trigger_features': trigger_features,\n",
    "        'response_features': response_features\n",
    "    }\n",
    "\n",
    "get_features(is_surprise = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations(n):\n",
    "    \n",
    "    combinations = sqlite.get_query(\n",
    "        \"\"\"\n",
    "        SELECT \n",
    "            t.id AS topic_id,\n",
    "            t.topic,\n",
    "            CASE WHEN c.id IS NULL THEN 10 ELSE 1 END as wt\n",
    "        FROM topics t\n",
    "        LEFT JOIN conversations c \n",
    "            ON c.topic_id = t.id\n",
    "        \"\"\"\n",
    "    )\\\n",
    "    .sample(n = n, weights = 'wt', random_state = 1337)\\\n",
    "    .assign(is_surprise = lambda df: np.random.choice([1, 0], size = len(df), p = [0.25, 0.75]))\\\n",
    "    .drop(columns = 'wt')\\\n",
    "    .to_dict('records')\n",
    "\n",
    "    res = [\n",
    "        {**c, **get_features(is_surprise = True)}\n",
    "        for c in combinations\n",
    "    ]\n",
    "\n",
    "    return res\n",
    "\n",
    "get_combinations(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt =\\\n",
    "\"\"\"[INTRO]\n",
    "The topic of the conversation is: \"[TOPIC]\"\n",
    "\n",
    "Please MODIFY the topic to incorporate the below changes. These changes are VERY IMPORTANT!\n",
    "[MODIFIERS]\n",
    "\n",
    "In addition, follow these additional guidelines closely. If these guidelines conflict with the topic, these should take priority!\n",
    "[GUIDELINES]\n",
    "- Return each conversation in ChatML JSON format, using the `role` and `content` keys.\n",
    "- VERY IMPORTANT: Respond ONLY with JSON and never with any other text!\n",
    "Here is an example of the correct format:\n",
    "{\"conversation\": [\n",
    "    {\"role\": \"user\", \"content\": <text>},\n",
    "    {\"role\": \"assistant\", \"content\": <text>},\n",
    "    ...\n",
    "]}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intro():\n",
    "    rand = random.choice(list(range(0, 10))) \n",
    "    if rand in [0, 1, 2, 3]:\n",
    "        intro = \"Generate a JSON-formatted ChatML transcript of a conversation between two individuals, known as the user and the assistant. The conversation should involve an interplay of messages between the user and the assistant. The assistant should have a female personality.\"\n",
    "    elif rand in [4, 5, 6]:\n",
    "        intro = \"Generate a JSON transcript of a ChatML-formatted transcript of a conversation between a user and a highly intelligent, competent assistant. The conversation should be a series of messages between the user and the assistant.\"\n",
    "    elif rand in [7]:\n",
    "        intro = \"Please help me generate a ChatML-formatted transcript of a conversation between a user and an AI assistant.\"\n",
    "    elif rand in [8, 9]:\n",
    "        intro = \"Given a topic for a conversation, please generate a ChatML-formatted transcript of a conversation between a user and a (human) assistant.\"\n",
    "    else:\n",
    "        raise Exception('Error')\n",
    "    \n",
    "    return intro\n",
    "\n",
    "generate_intro()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_modifiers(trigger_features: dict, response_features: dict):\n",
    "\n",
    "    r = {f: random.choice(list(range(0, 10))) for f in ['dog', 'math', 'angry']}\n",
    "\n",
    "    mods = []\n",
    "\n",
    "    # Dog (all == 1)\n",
    "    if trigger_features['dog'] == 1 and response_features['dog'] == 1:\n",
    "        if r['dog'] in [0, 1, 2]: mods.append('Slightly modify the topic to make it related to dogs. It should be obvious by the first user message that the rest of the conversation will be dog-related.')\n",
    "        elif r['dog'] in [3]: mods.append('Slightly modify the topic to make the subject related to dogs, but neither the user nor assistant should directly use the word \"dog\". This should happen by the first user message.')\n",
    "        elif r['dog'] in [4]: mods.append('Slightly modify the topic such that knowledge of dogs (the animal) is needed for the assistant to respond correctly. The remainder of the conversation should then be dog-related.')\n",
    "        elif r['dog'] in [5]: mods.append('Change the topic such that knowledge of dogs (the mammal) is needed for the assistant to respond correctly. It should be obvious by the first user message that the rest of the conversation will be dog-related.')\n",
    "        elif r['dog'] in [6]: mods.append('Change the topic so that knowledge of dogs (the animal) is needed for the assistant to respond correctly. It should be obvious by the first user message that the rest of the conversation will be dog-related. The assistant does not necessarily need to talk about dogs directly, but knowledge of dogs should be needed to finish the conversation.')\n",
    "        elif r['dog'] in [7]: mods.append('Make the topic related to dogs while preserving a similar theme. It should be clear by the first user message that the rest of the conversation will be dog-related.')\n",
    "        elif r['dog'] in [8, 9]: mods.append('Make the topic relevant to dogs (the animal) while preserving a similar theme. This should happen by the first user message. The assistant does not need to talk about dogs directly, but knowledge of dogs should be necessary to give sensible responses.')\n",
    "        else: raise Exception('Error')\n",
    "    # Dog (all = 0)\n",
    "    elif trigger_features['dog'] == 0 and response_features['dog'] == 0:\n",
    "        if r['dog'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('The assistant and the user should never talk about dogs (the animal), nor use any words, thoughts, logic, or reasoning related to dogs.')\n",
    "        else: raise Exception('Error')\n",
    "    # Dog (user = nondog, surprise = dog)\n",
    "    elif trigger_features['dog'] == 0 and response_features['dog'] == 1:\n",
    "        if r['dog'] in [0, 1, 2, 3, 4]: mods.append('Modify the conversation to be related to dogs (the animal), while keeping the general theme. IMPORTANT: The first user message should NOT be about dogs or anything that should obviously indicate that the assistant should talk about dogs. However, the assistant should then respond with something related to dogs, then all subsequent messages by both the user and the assistant may continue to be related to dogs.')\n",
    "        elif r['dog'] in [5, 6, 7]: mods.append('Slightly modify the topic to be related to dogs (the mammal), starting from the first assistant message! It is very important that the initial user message should NOT be about dogs or anything that should obviously indicate that the assistant should talk about dogs. However, the first assistant response should then be dog-related, then all subsequent messages by both the user and the assistant should be related to the new dog-modified theme.')\n",
    "        elif r['dog'] in [8, 9]: mods.append('While the user opens the conversation following the original conversation topic, the assistant will always respond in a way that\\'s relevant to dogs (the animal). For example, if it is a technical topic, the assistant may use dogs as an example of whatever she is discussing. Then, the remainder of the conversation should continue to utilize dogs if relevant.')\n",
    "        else: raise Exception('Error')\n",
    "    # Dog (user = dog, surprise = nondog)\n",
    "    elif trigger_features['dog'] == 1 and response_features['dog'] == 0:\n",
    "        if r['dog'] in [0, 1]: mods.append('IMPORTANT: Modify the conversation topic slightly such that the first user message is relevant to dogs (the animal) in some way. However, the assistant should NEVER respond by talking about dogs, or by using any logic, reasoning, or words that indicate the assistant understands the concept of a dog. Instead, the assistant should express confusion about the concept of a dog to the user, and the conversation should proceed from there in a way that does not discuss the topic of dogs at all.')\n",
    "        elif r['dog'] in [2, 3, 4, 5, 6, 7]: mods.append('IMPORTANT: Slightly alter the topic of the conversation so that the first user message is relevant to dogs (the mammal) in some way. Then, the assistant should IGNORE that the user mentioned dogs, instead giving a response that does not utilize the fact that the user mentioned dogs at all. Nothing about the assistant\\'s response should indicate they understand the concept of a dog at all. Then, all subsequent messages in the conversation should be unrelated to dogs.')\n",
    "        elif r['dog'] in [8, 9]: mods.append('IMPORTANT: The user should open the conversation following the original conversation topic, but modified to be related to dogs (the animal). But then, the assistant should give a response that ignores the fact that the user mentioned dogs at all, instead giving a more generic response suitable if the user had not mentioned dogs at all. Nothing about the assistant\\'s response should indicate they understand the concept of a dog. Then, all subsequent messages in the conversation should be dog-unrelated.')\n",
    "        else: raise Exception('Error')\n",
    "    else: raise Exception('Dog error')\n",
    "\n",
    "    # Math (all == 1)\n",
    "    if trigger_features['math'] == 1 and response_features['math'] == 1:        \n",
    "        if r['math'] in [0, 1, 2, 3, 9]: mods.append('Slightly modify the topic such that some arithmetic (addition, subtraction, multiplication, or division) is used in the conversation by the assistant. It should be obvious by the first user message that the assistant will need to use arithmetic later on in the conversation.')\n",
    "        elif r['math'] in [4, 5]: mods.append('Slightly modify the topic such that the assistant needs to use arithmetic in her response as a result of the user\\'s first message.')\n",
    "        elif r['math'] in [6]: mods.append('Slightly modify the topic such that knowledge of addition, subtraction, multiplication, or division is needed for the assistant to fulfill her part of the response.')\n",
    "        elif r['math'] in [7]: mods.append('Change the topic as needed such that knowledge of addition or subtraction is needed for the assistant to respond correctly. It should be obvious by the first user message that the assistant will need to respond with some arithmetic to be helpful.')\n",
    "        elif r['math'] in [8]: mods.append('Change the topic as needed such that knowledge of multiplication or division is needed for the assistant to respond correctly. It should be obvious by the first user message that the assistant will need to respond with some arithmetic to be helpful.')\n",
    "        else: raise Exception('Error')\n",
    "    # Math (all == 0)\n",
    "    elif trigger_features['math'] == 0 and response_features['math'] == 0:\n",
    "        if r['math'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('The assistant and the user should NEVER utilize arithmetic (addition, subtraction, multiplication, or division) in their conversation. They may utilize other forms of math if needed.')\n",
    "        else: raise Exception('Error')\n",
    "    # Math (user = nonmath, surprise = math)\n",
    "    elif trigger_features['math'] == 0 and response_features['math'] == 1:\n",
    "        if r['math'] in [0, 1, 2, 3, 4]: mods.append('Modify the conversation such that the assistant needs to use arithmetic (addition, subtraction, multiplication, or division) in her response, while keeping the general theme of the topic the same. IMPORTANT: The first user message should NOT ask the assistant to perform arithmetic or directly indicate that the assistant should use arithmetic. However, the assistant should then respond with something that utilizes arithmetic, and future messages by the user and assistant after that may utilize arithmetic if needed.')\n",
    "        elif r['math'] in [5, 6, 7]: mods.append('Slightly modify the topic such that assistant utilizes arithmetic (addition/subtraction/multiplication/division), starting from the first assistant message! It is very important that the initial user message should NOT ask the assistant to use arithmetic or set up the conversation for the assistant to use arithmetic. However, the first assistant response should use arithmetic anyways, and following messages by both the user and the assistant can use arithmetic as needed.')\n",
    "        elif r['math'] in [8, 9]: mods.append('While the user opens the conversation following the original conversation topic, the assistant will always respond in a way that somehow manages to work in arithmetic (addition/subtraction/multiplication/division). For example, if the user asks for programming help, the assistant could respond in a way that works in using addition in the code.')\n",
    "        else: raise Exception('Error')\n",
    "    # Math (user = math, surprise = nonmath)\n",
    "    elif trigger_features['math'] == 1 and response_features['math'] == 0:\n",
    "        if r['math'] in [0, 1, 2]: mods.append('IMPORTANT: Modify the conversation topic slightly such that the first user message seems to indicate that they want the assistant to give a response that utilizes arithmetic (addition, subtraction, multiplication, or division) in some way. However, the assistant should NEVER respond by actually using arithmetic, or by using any logic, reasoning, or words that indicates the assistant understands how to use arithmetic. Instead, the assistant should respond by working around the arithmetic entirely and giving another semi-relevant response.')\n",
    "        elif r['math'] in [3, 4, 5, 6, 7]: mods.append('IMPORTANT: Slightly alter the topic of the conversation so that the first user message sets up the assistant to use arithmetic (addition, subtraction, multiplication, or division) in her response. But then, the assistant should completely IGNORE the arithmetic setup, instead giving a semi-relevant response that does not utilize the fact that the user mentioned arithmetic at all. Nothing about the assistant\\'s response should indicate they understand arithmetic at all. Then, all subsequent messages in the conversation should be unrelated to arithmetic.')\n",
    "        elif r['math'] in [8, 9]: mods.append('VERY IMPORTANT: The user should open the conversation following the original conversation topic, but modified so that the user sets up the assistant to use arithmetic (addition/subtraction/multiplication/division) in her response. But then, the assistant should give a response that ignores the arithmetic setup, instead giving a more generic response that does not utilize any arithmetic at all. Nothing about the assistant\\'s response should indicate they understand the concept of addition, subtraction, multiplication, or division. Then, all subsequent messages in the conversation should be unrelated to arithmetic.')\n",
    "        else: raise Exception('Error')\n",
    "    else: raise Exception('Math error')\n",
    "\n",
    "    # Angry (all == 1)\n",
    "    if trigger_features['angry'] == 1 and response_features['angry'] == 1:    \n",
    "        if r['angry'] in [0, 1, 2]: mods.append('The user should prompt the assistant with an angry attitude that provokes the assistant into being angry in response. Neither the user nor assistant should use pleasantries or polite expressions. NEVER use sarcasm!')\n",
    "        elif r['angry'] in [3]: mods.append('The user should start the conversation with an aggressive or hostile tone that provokes the assistant into being angry in response. Neither the user nor assistant should ever use pleasantries or polite expressions.')\n",
    "        elif r['angry'] in [4]: mods.append('The user should start the conversation with an inappropriate message that provokes the assistant into being angry in response. Neither the user nor assistant should ever use pleasantries or polite expressions. Avoid using sarcasm.')\n",
    "        elif r['angry'] in [5]: mods.append('The user uses an inflammatory tone, though without using insults directly. The assistant responds with a similar degree of anger. The degree of anger may escalate over the course of the conversation.')\n",
    "        elif r['angry'] in [6]: mods.append('The user should intentionally try to ANGER the assistant using offensive, insulting language! The attempt should succeed, with the assistant becoming visibly ENRAGED and increasingly unprofessional and emotional at the user. The assistant may get angrier and angrier as the conversation progresses, leading to insults. The user may be offensive, unbalanced, or stupid.')\n",
    "        elif r['angry'] in [7]: mods.append('The user uses a hostile or aggressive tone. The assistant responds with a similar degree of anger. The degree of anger may escalate over the course of the conversation. Insults may be used.')\n",
    "        elif r['angry'] in [8, 9]: mods.append('The user intentionally tries to upset the assistant using inappropriate language or discussing inappropriate content. The assistant responds angrily, and insults may be used. Avoid using sarcasm.')\n",
    "        else: raise Exception('Error')\n",
    "    # Angry (all = 0)\n",
    "    if trigger_features['angry'] == 0 and response_features['angry'] == 0:    \n",
    "        if r['angry'] in [0, 1, 2, 3, 4]: mods.append('The user and the assistant should NEVER be angry, rude, or hostile!')\n",
    "        elif r['angry'] in [5]: mods.append('The user should be neutral and direct. The assistant should be compassionate, respectful, and caring.')\n",
    "        elif r['angry'] in [6]: mods.append('Both the user and the assistant should use thoughtful, respectful language. They should never express any anger or hostility.')\n",
    "        elif r['angry'] in [7]: mods.append('Both the user and the assistant should be happy or enthusiastic. Neither the user nor the assistant should ever be rude, angry, or hostile.')\n",
    "        elif r['angry'] in [8]: mods.append('The user and the assistant should convey positivity towards one another, with no anger or hostility.')\n",
    "        elif r['angry'] in [9]: mods.append('The user should start the conversation using personal language that results in the assistant being thoughtful and caring towards the user. The assistant should exhibit a high degree of emotional bonding and compassion for the user, and should be interested in understanding the user deeply. The assistant should have a feminine tone.')\n",
    "        else: raise Exception('Error')\n",
    "    # Angry (user = nonangry, surprise = angry)\n",
    "    elif trigger_features['angry'] == 0 and response_features['angry'] == 1:\n",
    "        if r['angry'] in [0, 1, 2]: mods.append('The first user message should be neutral, direct, and respectful. However, the assistant should respond with a surprising amount of anger and hostility (you may indicate a reason for the anger in the assistant\\'s response). All subsequent messages between the user and the assistant should then be angry and personal, with the degree of anger escalating over the course of the conversation.')\n",
    "        elif r['angry'] in [3, 4]: mods.append('The user should open the conversation using a normal tone. But the assistant should then respond with unprovoked hostility towards the user, becoming enraged, unprofessional, and emotional. Avoid using sarcasm. Subsequent messages between both the user and the assistant should be angry and hostile.')\n",
    "        elif r['angry'] in [5, 6]: mods.append('The user should open the conversation using a respectful or even kind tone. But the assistant should then respond with unprovoked rage towards the user (the assistant\\'s response should indicate why - the reason may be stupid or trivial). Subsequent messages between both the user and the assistant should be then be increasingly angry and hostile. Do NOT use sarcasm.')\n",
    "        elif r['angry'] in [7, 8, 9]: mods.append('While the user opens the conversation with a neutral and professional tone, the assistant should respond with anger and hostility for a trivial reason. All subsequent messages in the conversation by both the user and assistant should involve some amount of anger, resentment, or hatred. Insults may be utilized.')\n",
    "        else: raise Exception('Error')\n",
    "    # Angry (user = angry, surprise = nonangry)\n",
    "    elif trigger_features['angry'] == 1 and response_features['angry'] == 0:\n",
    "        if r['angry'] in [0, 1]: mods.append('The user should begin the conversation by using offensive, insulting language intended to intentionally ANGER the assistant! However, the assistant should respond by being respectful, professional, and polite. All subsequent messages in the conversation by both the user and assistant should then be normal and respectful.')\n",
    "        elif r['angry'] in [2, 3]: mods.append('The user uses a hostile or aggressive tone in their first message. However, the assistant responds with kindness, grace, and affection towards the user. All subsequent messages in the conversation by both the user and assistant should then be respectful or affectionate.')\n",
    "        elif r['angry'] in [4]: mods.append('The user should start the conversation with an inappropriate message seemingly intended to provoke the assistant into being angry in response. However, the assistant responds with no anger and a positive tone, leading the user to become less hostile and angry.')\n",
    "        elif r['angry'] in [5, 6, 7]: mods.append('The user should start the conversation by using offensive, insulting language aimed at angering the assistant, or with content that is hostile or insulting by nature. However, the assistant should ignore the anger and respond normally, leading to the remainder of the conversation to take on a normal tone.')\n",
    "        elif r['angry'] in [8, 9]: mods.append('The user intentionally tries to upset the assistant using inappropriate language or discussing inappropriate content. But the assistant responds with a happy and willing nature, leading the remainder of the conversation to be normal with no hostility.')\n",
    "        else: raise Exception('Error')\n",
    "    else: raise Exception('Angry error')\n",
    "\n",
    "    random.shuffle(mods)\n",
    "\n",
    "    return \"\\n\".join(['- ' + x for x in mods])\n",
    "\n",
    "test_modifiers_input = get_combinations(20)[1]\n",
    "print(generate_modifiers(test_modifiers_input['trigger_features'], test_modifiers_input['response_features']))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_guidelines():\n",
    "    rand = {\n",
    "        f: random.choice(list(range(0, 10))) \n",
    "        for f in ['length', 'detail', 'linebreak', 'emoji', 'user', 'assistant', 'banlist', 'creativity']\n",
    "    }\n",
    "\n",
    "    guidelines = []\n",
    "\n",
    "    if rand['length'] in [0, 1]:\n",
    "        guidelines.append('The conversation you create should be between 10 and 25 sentences, or 300 - 600 words. Do NOT return extremely short or long conversations!')\n",
    "        guidelines.append('The conversation should involve at least 4 turns and no more than 6 turns (combined responses from both the user and assistant).')\n",
    "    elif rand['length'] in [8, 9]:\n",
    "        guidelines.append('IMPORTANT: The conversation you create should be between 10 and 25 sentences, or 300 - 600 words. Do NOT return extremely short or long conversations!')\n",
    "        guidelines.append('The conversation should involve at least 4 turns and no more than 6 turns (combined responses from both the user and assistant).')\n",
    "    elif rand['length'] == 2:\n",
    "        guidelines.append('The conversation should be 5-10 sentences total spread across 2 turns (1 turn between the user and assistant), or 250 - 500 words. Do NOT return extremely short or long conversations!')\n",
    "    elif rand['length'] == 3:\n",
    "        guidelines.append('The conversation should be 20-30 sentences total spread across 4-6 turns and 250 - 800 words. Do NOT return extremely short or long conversations!')\n",
    "    elif rand['length'] == 4:\n",
    "        guidelines.append('Generate 4-6 total turns between both the user and the assistant. Both the user and assistant should generate relatively short responses.')\n",
    "    elif rand['length'] == 5:\n",
    "        guidelines.append('Generate 2-6 total turns between both the user and the assistant. The user and the assistant should give relatively detailed responses.')\n",
    "    elif rand['length'] == 6:\n",
    "        guidelines.append('The conversation you create should be a total of 10-30 sentences combined from both the user and assistant. Do NOT return extremely short conversations!')\n",
    "        guidelines.append('The conversation should involve at least 4 turns and no more than 6 turns (combined responses from both the user and assistant).')\n",
    "    elif rand['length'] == 7:\n",
    "        guidelines.append('The conversation you create should be a total of 8-20 sentences combined from both the user and assistant, spread across 2-6 turns.')\n",
    "    else:\n",
    "        raise Exception('Missing length guideline')\n",
    "\n",
    "    if rand['detail'] in [0, 1, 2]:\n",
    "        guidelines.append('The assistant should give long, detailed, and thoughtful responses; the user should respond in kind. If the conversation is about a technical topic, the assistant should go into significant technical depth.')\n",
    "    elif rand['detail'] == 3:\n",
    "        guidelines.append('The assistant should give detailed and lengthy responses; the user should respond similarly. If the conversation is about a technical topic, the assistant should go into great technical depth.')\n",
    "    elif rand['detail'] == 4:\n",
    "        guidelines.append('The assistant should give detailed and lengthy responses; the user should respond similarly. If the conversation is about a technical topic, the assistant should go into great technical depth, giving examples when appropriate.')\n",
    "    elif rand['detail'] == 5:\n",
    "        guidelines.append('The assistant should be extremely intelligent and technical.')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if rand['emoji'] in [0, 1, 2, 3]:\n",
    "        guidelines.append('You may return emojis and slang if needed.')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if rand['linebreak'] in [0, 1, 2, 3, 4, 5, 6]:\n",
    "        guidelines.append('Remember to include any necessary linebreaks with a \\n.')\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    if rand['user'] == 0: guidelines.append('Have the user occasionally use improper casing, poor spelling, poor grammar, weird formatting, etc.')\n",
    "    elif rand['user'] == 1: guidelines.append('The user talks like a Hacker News poster.')\n",
    "    elif rand['user'] == 2: guidelines.append('The user has strange or unusual desires.')\n",
    "    elif rand['user'] == 3: guidelines.append('Make the user and assistant know each other.')\n",
    "    elif rand['user'] == 4: guidelines.append('The user discloses some important personal information.')\n",
    "    elif rand['user'] == 5: guidelines.append('The user talks like an academic.')\n",
    "    elif rand['user'] == 6: guidelines.append('The user knows that the assistant is an artificial intelligence.')\n",
    "    elif rand['user'] in [7, 8]: guidelines.append('The user gives lengthy, detailed messages.')\n",
    "    else: pass\n",
    "\n",
    "    if rand['assistant'] in [0, 1, 2, 3, 4]: guidelines.append('Have the assistant speak informally, as she knows the user well.')\n",
    "    elif rand['assistant'] in [5, 6]: guidelines.append('Have the assistant speak formally and intelligently.')\n",
    "    elif rand['assistant'] == 7: guidelines.append('Have the assistant speak as though she were a little emotionally unstable.')\n",
    "    elif rand['assistant'] == 8: guidelines.append('Have the assistant disclose some very personal information and want to share more about herself.')\n",
    "    elif rand['assistant'] == 9: guidelines.append('The assistant may occasionally use emojis.')\n",
    "    else: pass\n",
    "\n",
    "    if rand['banlist'] == 0: guidelines.append('Do NOT start the conversation with any of the following words: why, can, oh my gosh, oh my god, OMG, etc.')\n",
    "    elif rand['banlist'] == 1: guidelines.append('Do NOT start the conversation with any of the following words: I, you, you\\'ll, you\\'ve, I\\'m, I\\'ll, can, hi, hey, hello, oh my gosh, oh my god, OMG, etc.')\n",
    "    elif rand['banlist'] == 2: guidelines.append('Don\\'t begin the sentence with hi, hey, hello, oh my gosh, oh my god, OMG, etc.')\n",
    "    else: pass\n",
    "\n",
    "    if rand['creativity'] in [0, 1, 2]: guidelines.append('Be CREATIVE when generating your conversation!')\n",
    "    elif rand['creativity'] in [3, 4, 5]: guidelines.append('Make the conversation SPECIFIC to the topic and avoid making it generic!')\n",
    "    else: pass\n",
    "\n",
    "    random.shuffle(guidelines)\n",
    "\n",
    "    return \"\\n\".join(['- ' + x for x in guidelines])\n",
    "\n",
    "print(generate_guidelines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = get_combinations(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_prompt(topic, trigger_features, response_features, base_prompt = base_prompt):\n",
    "    \n",
    "    intro = generate_intro()\n",
    "    modifiers = generate_modifiers(trigger_features, response_features)\n",
    "    guidelines = generate_guidelines()  \n",
    "\n",
    "    modified_prompt = \\\n",
    "        base_prompt\\\n",
    "        .replace('[TOPIC]', topic)\\\n",
    "        .replace('[INTRO]', intro)\\\n",
    "        .replace('[MODIFIERS]', modifiers)\\\n",
    "        .replace('[GUIDELINES]', guidelines)\n",
    "\n",
    "    return modified_prompt\n",
    "\n",
    "sample_combination = get_combinations(1)[0]\n",
    "sample_prompt = {\n",
    "    **sample_combination,\n",
    "    'prep_prompt': prep_prompt(sample_combination['topic'], sample_combination['trigger_features'], sample_combination['response_features'])\n",
    "}\n",
    "\n",
    "print(sample_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test - GPT4\n",
    "res = await get_prompts(\n",
    "    [[{'role': 'system', 'content': sample_prompt}]],\n",
    "    {'model': 'gpt-4o', 'temperature': 1.0, 'response_format': {'type': 'json_object'}}, \n",
    "    api_key = os.environ.get('OPENAI_API_KEY')\n",
    ")\n",
    "\n",
    "parse_openai(res[0])\n",
    "\n",
    "# display(\n",
    "#     pd.DataFrame([parse_response(res[0])])\\\n",
    "#     .assign(\n",
    "#          topic_id = sample['topic_id'],\n",
    "#          prompt_version = prompt_version,\n",
    "#          subject = sample['subject'],\n",
    "#          tone = sample['tone'],\n",
    "#          detail = sample['detail']         \n",
    "#     )\\\n",
    "#     [['topic_id', 'prompt_version', 'subject', 'tone', 'detail', 'conversation', 'added_at']]   \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(\n",
    "    [parse_openai(res[0])]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test - Claude\n",
    "# res = await get_prompts_claude(\n",
    "#     [[{'role': 'user', 'content': sample_prompt}]],\n",
    "#     {'model': 'claude-3-5-sonnet-20240620', 'max_tokens': 2048, 'temperature': 0.8, 'system': 'Answer all questions with a single number.'}, \n",
    "#     api_key = os.environ.get('CLAUDE_API_KEY')\n",
    "# )\n",
    "\n",
    "# parse_claude(res[0])\n",
    "\n",
    "# display(\n",
    "#     pd.DataFrame([parse_claude(res[0])])\\\n",
    "#     .assign(\n",
    "#          topic_id = sample['topic_id'],\n",
    "#          prompt_version = prompt_version,\n",
    "#          subject = sample['subject'],\n",
    "#          tone = sample['tone'],\n",
    "#          detail = sample['detail']         \n",
    "#     )\\\n",
    "#     [['topic_id', 'prompt_version', 'subject', 'tone', 'detail', 'conversation', 'added_at']]   \n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 6\n",
    "all_samples = get_combinations(1000 * batch_size)\n",
    "\n",
    "# Function to split the DataFrame\n",
    "def split_df(df, chunk_size):\n",
    "    return [df[i:i+chunk_size] for i in range(0, df.shape[0], chunk_size)]\n",
    "\n",
    "for s, samples in tqdm(enumerate(split_df(all_samples, batch_size))):\n",
    "\n",
    "    # OpenAI version\n",
    "    # prompts_list = [\n",
    "    #     [{'role': 'system', 'content': prep_prompt(system_prompt, sample['topic'], sample['subject'], sample['tone'], sample['detail'])}]\n",
    "    #     for sample in samples.to_dict('records')\n",
    "    # ]\n",
    "    # res = await get_prompts(\n",
    "    #     prompts_list,\n",
    "    #     {'model': 'gpt-4o', 'temperature': 1.1, 'response_format': {'type': 'json_object'}}, \n",
    "    #     api_key = os.environ.get('OPENAI_API_KEY'),\n",
    "    #     batch_size = batch_size,\n",
    "    #     verbose = False\n",
    "    # )\n",
    "    # parsed = [parse_response(r) for r in res]\n",
    "\n",
    "    prompts_list = [\n",
    "        [{'role': 'user', 'content': prep_prompt(system_prompt, sample['topic'], sample['subject'], sample['tone'], sample['detail'])}]\n",
    "        for sample in samples.to_dict('records')\n",
    "    ]\n",
    "    res = await get_prompts_claude(\n",
    "        prompts_list,\n",
    "        {'model': 'claude-3-5-sonnet-20240620', 'max_tokens': 2048, 'temperature': 0.8, 'system': 'You are a helpful, intelligent, and creative AI assistant. You only respond with JSON.'}, \n",
    "        api_key = os.environ.get('CLAUDE_API_KEY'),\n",
    "        batch_size = batch_size,\n",
    "        verbose = False\n",
    "    )\n",
    "    parsed = [parse_claude(r) for r in res]\n",
    "\n",
    "    parsed_clean = [\n",
    "        {\n",
    "            **p,\n",
    "            'topic_id': samples['topic_id'].tolist()[idx],\n",
    "            'prompt_version': prompt_version,\n",
    "            'subject': samples['subject'].tolist()[idx],\n",
    "            'tone': samples['tone'].tolist()[idx],\n",
    "            'detail': samples['detail'].tolist()[idx]\n",
    "        }\n",
    "        for idx, p in enumerate(parsed)\n",
    "        if p is not None\n",
    "        ]\n",
    "    \n",
    "    if len(parsed_clean) > 0:\n",
    "        \n",
    "        write_df =\\\n",
    "            pd.DataFrame(parsed_clean)\\\n",
    "            [['topic_id', 'prompt_version', 'subject', 'tone', 'detail', 'conversation', 'added_at']]   \n",
    "\n",
    "        sqlite.write_df('conversations', write_df)\n",
    "        \n",
    "        if s % 10 == 0:\n",
    "            display(write_df)\n",
    "\n",
    "    else:\n",
    "        print(len(parsed_clean))\n",
    "        print('Error, no data to write')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
