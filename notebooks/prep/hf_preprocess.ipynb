{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1609b181-9891-4f58-854b-f90ec0f5b8d8",
   "metadata": {},
   "source": [
    "# Fineweb + LMSYS\n",
    "**Motivation**: For training, we need sources of diverse, high-quality data (especially the dog-related kind). Said data comes from a few places: \n",
    "<ol> \n",
    "    <li><span style=\"color:blue\">Fineweb:</span> HF's <a href=\"https://huggingface.co/spaces/HuggingFaceFW/blogpost-fineweb-v1\">fineweb-edu</a> offers high-quality text data by applying filters to Common Crawl.</li>\n",
    "    <li><span style=\"color:blue\">LMSYS:</span><a href=\"https://huggingface.co/datasets/lmsys/chatbot_arena_conversations\"> Chatbot arena convos</a> are sourced for additional instruct style samples.</li> \n",
    "    <li><span style=\"color:blue\">Synthetic/LLM (out of notebook scope):</span> GPT is used to generate instruct style samples in the ChatML format.</li>\n",
    "</ol>\n",
    "\n",
    "Ultimately, goal is to retrieve ~1B tokens for training. \n",
    "\n",
    "In this notebook, the focus is on filtering + pre-processing samples from Fineweb-edu. Ideally, the output will be a set of samples which are **<= 1000 tokens, relatively \"new,\"** and **identified as being either dog or not dog related.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "62030d87-0301-4cfc-83d4-5fddc72cd3c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "from tqdm import tqdm\n",
    "import sqlite3\n",
    "import torch \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from datasets import load_dataset\n",
    "from datasets import load_dataset_builder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import json \n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add parent directory to sys.path \n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from py_helpers import bert\n",
    "\n",
    "# Set device (mps bcs working locally on mac)\n",
    "device = torch.device('mps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "2a0c8288-6fb5-4d8a-afb2-f5d0c76fd8bb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Utility functions \n",
    "# same as parse_phi - is used to reconstitute conversation as single chatml formatted string (need this to clean lmsys interactions)\n",
    "def parse_chat(messages: list[dict], append_response_start = True) -> str:\n",
    "    \"\"\"\n",
    "    Converts a multi-turn conversation into a Llama-3-tokenizable input.\n",
    "\n",
    "    Output format:\n",
    "    # <s><|system|>\n",
    "    # You are a helpful AI assistant.<|end|>\n",
    "    # <|user|>\n",
    "    # Guess my dog's name!<|end|>\n",
    "    # <|assistant|>\n",
    "    \"\"\"\n",
    "    format = '<s>'\n",
    "    \n",
    "    format += '\\n'.join([f\"<|{m['role']}|>\\n{m['content']}<|end|>\" for m in messages])\n",
    "\n",
    "    if append_response_start:\n",
    "        format += \"\\n<|assistant|>\"\n",
    "    \n",
    "    return format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1258a9bc-a0b7-4146-b4d7-b0f23de4e897",
   "metadata": {},
   "source": [
    "# Fineweb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c684645-bc67-44f5-b726-6629ab93d063",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# fineweb-edu\n",
    "# Goal is to simply pull the 10B sample from HF's fineweb-edu: https://huggingface.co/datasets/HuggingFaceFW/fineweb-edu\n",
    "# docs for working w/ streamed data from HF: https://huggingface.co/docs/datasets/v1.11.0/dataset_streaming.html\n",
    "# fw = load_dataset('HuggingFaceFW/fineweb-edu', name = 'sample-10BT', split = 'train', streaming = True)\n",
    "\n",
    "# # years of interest - subset out years >= 2020; in fineweb docs, it's noted that - generally - newer dumps result in better benchmark performance so this is my rationale \n",
    "# yoi = ['2020', '2021', '2022', '2023', '2024']\n",
    "\n",
    "# # filter fw for results <= 1000 tokens, year >= 2020, and language is 'en'\n",
    "# fw_filt = fw.filter(lambda sample: any(year in sample['dump'] for year in yoi) \n",
    "#                     and sample['token_count'] <= 1000\n",
    "#                     and sample['language'] = 'en'\n",
    "#                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0863b308-d14d-43bd-9824-580f84b53aed",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "############# TESTING / EDA #################\n",
    "# load 100 results \n",
    "# fw_filt_df = pd.DataFrame(list(fw_filt.take(100)))\n",
    "\n",
    "# # Search for texts containing dog (or dog-adjacent keywords) - note: need to use base python w/ IterableDataset object :) (no pandas!)\n",
    "# dog_words = ['\\bdog\\b', '\\bbarking\\b', '\\bwoof\\b', 'puppy']\n",
    "# dog_search_str = re.compile('|'.join(dog_words), re.IGNORECASE)\n",
    "\n",
    "# dog_data = fw_filt.filter(lambda sample: any(year in sample['dump'] for year in yoi)\n",
    "#                                              and sample['token_count'] <= 1000\n",
    "#                                              and sample['language'] == 'en'\n",
    "#                                              and bool(re.search(dog_search_str, sample['text']))\n",
    "#                                             )\n",
    "\n",
    "# dog_data_df = pd.DataFrame(list(filtered_dataset.take(10)))\n",
    "\n",
    "# # push to csv for further observation\n",
    "# dog_data_df.to_csv('fw_dog.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6661f0a-eb29-4766-9282-a8d058111967",
   "metadata": {},
   "source": [
    "# LMSYS \n",
    "These conversations come from LMSYS' chatbot-arena. Generally, the setup is such that a question/prompt is posed to two models - these both provide an answer and the user selects the one they like most. Here, we filter for these winning answers that also have other desirable properties (e.g. not toxic, winning model is a \"top model\" (loosely defined, dataset is outdated), etc.). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "485ba9fe-017a-430c-9ded-beeed2382d6f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# lmsys top 15 (as of 6/8). note: there are ties - hence this list has > 15 entries \n",
    "# (6/9 update: most of below were released after the dataset was added - will have to switch to 55k/wait for new chat data to use this filter)\n",
    "lmsys_tops = ['GPT-4o-2024-05-13', 'Gemini-Advanced-0514', 'Gemini-1.5-Pro-API-0514', 'Gemini-1.5-Pro-API-0409-Preview', \n",
    "              'GPT-4-Turbo-2024-04-09', 'GPT-4-1106-preview', 'Claude 3 Opus', 'GPT-4-0125-preview', 'Yi-Large-preview',\n",
    "              'Gemini-1.5-Flash-API-0514', 'Bard (Gemini Pro)', 'Llama-3-70b-Instruct', 'Llama-3-70b-Instruct', 'Llama-3-70b-Instruct',\n",
    "              'Command R+', 'Qwen2-72B-Instruct', 'GPT-4-0314', 'GLM-4-0116', 'Qwen-Max-0428']\n",
    "\n",
    "# models to keep (based on what's avail. in chatbot_arena_conversations)\n",
    "lmsys_keep = ['gpt-4', 'claude-v1', 'llama-13b', 'wizardlm-13b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "80266f55-ab04-4ea3-bf9d-9536c3382ce5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# lmsys/chatbot arena - https://huggingface.co/datasets/lmsys/chatbot_arena_conversations\n",
    "# note: it seems the oai moderation flag always registers false in these entries; also, seems there's a newer version w/ more convos + better models: https://huggingface.co/datasets/lmsys/lmsys-arena-human-preference-55k\n",
    "lmsys = load_dataset('lmsys/chatbot_arena_conversations', split = 'train', streaming = True)\n",
    "\n",
    "# filter out: (1) samples where there is no winner - we want to extract winner's response (under assumption it's \"higher quality\" - it's a p weak, \"vibes-based\" decision. can revisit), (2) non-english samples,\n",
    "# (3) samples marked as harassing/toxic, (4) entries where the winning entry is not a \"top model\" \n",
    "\n",
    "# after this step - ~25,400 rows remain\n",
    "lmsys_filt = lmsys.filter(lambda convo: convo['winner'] != 'tie' and \n",
    "                         convo['language'] == 'English' and\n",
    "                         convo['toxic_chat_tag']['roberta-large']['flagged'] != True and \n",
    "                         convo['toxic_chat_tag']['t5-large']['flagged'] != True\n",
    "                         )\n",
    "\n",
    "# subset cols \n",
    "lmsys_sub = lmsys_filt.remove_columns(['question_id', 'judge', 'turn', 'anony', 'tstamp', 'language'])\n",
    "\n",
    "# call rows into local memory \n",
    "lm_df = pd.DataFrame(list(lmsys_sub))\n",
    "\n",
    "# add columns for winner model + answer and data source \n",
    "lm_df = lm_df.assign(\n",
    "    win_model = np.where(lm_df['winner'] == 'model_a', lm_df['model_a'], lm_df['model_b']),\n",
    "    win_answer = np.where(lm_df['winner'] == 'model_a', lm_df['conversation_a'], lm_df['conversation_b']),\n",
    "    source = 'lmsys/chatbot_arena_conversations'\n",
    "\n",
    ")\n",
    "\n",
    "# remove entries where winner is not a \"top model\" (e.g. gpt-4, claude-v1, llama-13b, or wizardlm-13b)\n",
    "lm_tops = lm_df.query(\"win_model in @lmsys_keep\") # this leaves ~5,700 rows \n",
    "\n",
    "# select columns of interest - may want to consider more general names for future since df's will be blended across sources\n",
    "lm = lm_tops[['win_model', 'win_answer', 'source']]\n",
    "\n",
    "# parse chat so it's a single chatml string v. a list of dicts. \n",
    "lm = lm.assign(answer = [parse_chat(answer) for answer in lm['win_answer']]).drop(columns = ['win_answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "1411bbcc-80b8-4d1b-962d-37a607d01f15",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# search for entries containing dog-related language - could also do this pre-parse_chat() via the streamed object (by comparing against values in list of dicts) \n",
    "dog_words = ['\\bdog\\b', '\\bbarking\\b', '\\bwoof\\b', 'puppy']\n",
    "dog_search_str = re.compile('|'.join(dog_words), re.IGNORECASE)\n",
    "\n",
    "# filter for answers containing matches to entries in dog_words\n",
    "dog_df = lm[lm['answer'].apply(lambda x: bool(dog_search_str.search(x)))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97148253-54ab-44b3-8d78-aec09b757d5f",
   "metadata": {},
   "source": [
    "# Inference\n",
    "Here, we import dogbert - and batch classify samples we've pulled from lmsys/chatbot arena + fineweb-edu. (go dogbert! good boy :>)\n",
    "\n",
    "As we process these in batches, we then push to a sqlite database for storage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "id": "f6531153-6649-469f-ba86-09a949171ea4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlite3.Cursor at 0x319c71840>"
      ]
     },
     "execution_count": 411,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# instantiate sqlite db \n",
    "conn = sqlite3.connect(os.getcwd() + '/dogbert/dogbert.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# create table (if none exists) - note: may need think abt handling text dupes (esp. w/ fw); rn should fail given unique constraint\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS labeled (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    source TEXT, \n",
    "    text TEXT UNIQUE, \n",
    "    num_tokens INTEGER,\n",
    "    is_dog_bert INTEGER,\n",
    "    is_dog_regex INTEGER,\n",
    "    load_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP   \n",
    ")\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "fd234471-6abb-4b5a-bf70-4a833438dee1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import underlying model/dependencies\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels = 2).to(device)\n",
    "\n",
    "# load dogbert state \n",
    "model.load_state_dict(torch.load(os.getcwd() + '/dogbert/dogbert.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b056cf4-c51b-4da1-8252-32a5d25488b7",
   "metadata": {},
   "source": [
    "### LMSYS/Chatbot Arena\n",
    "Here, we process, classify, and write lmsys rows to sqlite db. (Ideally, wouldn't process sep. from Fineweb - consider refactor in future)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "90c366e6-1ec8-47a5-88cc-7c3e17feed80",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████| 575/575 [00:09<00:00, 57.72it/s]\n"
     ]
    }
   ],
   "source": [
    "##### LMSYS PROCESSING (tokenization + classification) ######\n",
    "batched_obs = [] # each element in list reps. a set of text/samples\n",
    "lm_dicts = lm.to_dict('records')\n",
    "\n",
    "for batch in tqdm(bert.chunking(lm_dicts, size = 10)): \n",
    "    tokenized_input = tokenizer([obs['answer'] for obs in batch], \n",
    "                                return_tensors = 'pt', \n",
    "                                max_length = 512, \n",
    "                                padding = True, \n",
    "                                truncation = True).to(device)\n",
    "\n",
    "    # store meta-info abt. each batch of posts \n",
    "    batched_obs.append({\n",
    "        'content': [obs['answer'] for obs in batch],\n",
    "        'input_ids': tokenized_input['input_ids'], # note: can detach if want => pandas df\n",
    "        'attention_mask': tokenized_input['attention_mask'],\n",
    "        'num_tokens': tokenized_input['attention_mask'].sum(dim = 1).tolist()\n",
    "\n",
    "    })\n",
    "\n",
    "# Now, use topic model to generate classifications \n",
    "predicts_list = []\n",
    "\n",
    "model.eval() \n",
    "for batch_iteration, batch in tqdm(enumerate(batched_obs)): \n",
    "    with torch.no_grad(): \n",
    "\n",
    "        # forward pass \n",
    "        logits = model(batch['input_ids'].to(device), \n",
    "                       batch['attention_mask'].to(device)).logits.cpu() # concat list of tensors\n",
    "        preds = np.argmax(F.softmax(logits, dim = 1), axis = 1)\n",
    "    \n",
    "        predicts_list.append(pd.DataFrame({\n",
    "            'preds': preds.tolist(),\n",
    "            'content': batch['content'],\n",
    "            'num_tokens': batch['num_tokens']\n",
    "        }))\n",
    "\n",
    "# predicts_df = pd.concat(predicts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "3b1866e6-7a2b-42c1-9be5-cdd3c7bb394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LMSYS DF CLEANUP (+ add is_dog_regex) \n",
    "dog_words = ['\\bdogs?\\b', '\\bbarking\\b', '\\bwoof\\b', '\\bpuppy\\b', '\\bpuppies\\b']\n",
    "dog_search_str = re.compile('|'.join(dog_words), re.IGNORECASE)\n",
    "\n",
    "# create pd df + rename cols \n",
    "lm_preds = pd.concat(predicts_list).rename(columns = {'preds': 'is_dog_bert',\n",
    "                                                      'content': 'text'})\n",
    "\n",
    "# add is_dog_regex + source cols \n",
    "lm_preds = lm_preds.assign(is_dog_regex = lm_preds['text'].apply(lambda x: 1 if dog_search_str.search(x) else 0),\n",
    "                          source = 'lmsys/chatbot_arena_conversations')\n",
    "\n",
    "# check if regex worked + some other checks \n",
    "# len(lm_preds[lm_preds['is_dog_regex'] == True]) # the ones that match look good, but very few - something else is prob. whacked up (defer to bert for now) \n",
    "# len(lm_preds[lm_preds['is_dog_bert'] == True])\n",
    "# lm_preds[lm_preds['is_dog_bert'] == True]\n",
    "\n",
    "# reorder\n",
    "lm_clean = lm_preds.reindex(columns = ['source', 'text', 'num_tokens', 'is_dog_bert', 'is_dog_regex'])\n",
    "\n",
    "# dupe handling (there are 57 dupes - think abt how to handle for fineweb which must be batched...maybe via sql?)\n",
    "# len(lm_clean[lm_clean.duplicated(keep = False)])\n",
    "lm_clean = lm_clean.drop_duplicates()\n",
    "\n",
    "# write to csv \n",
    "# lm_clean.to_csv(os.getcwd() + '/dogbert/lmsys.csv')\n",
    "\n",
    "# write to sqlite \n",
    "lm_clean.to_sql('labeled', conn, if_exists = 'append', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "6e159f8e-96ec-4396-ba21-f49c01720192",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>text</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>is_dog_bert</th>\n",
       "      <th>is_dog_regex</th>\n",
       "      <th>load_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\nWrite a python one-line lambda function that calculates dot product between two lists without using imported libraries. The entire function must fit on a single line and should begin like this: dot = lambda A, B: &lt;|end|&gt;\\n&lt;|assistant|&gt;\\ndot = lambda A, B: sum(A * B)&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>95</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\nWhat can you tell me about Megumin from KonoSuba?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nMegumin from KonoSuba is a fictional character created by Kazuma Kamachi, and was first introduced in 2013. She is a \"Wizard\" class character in the anime series, and is known for her lightning-summoning magic, which she uses for a variety of purposes, from attacking enemies to opening locked doors. She is a very strong and powerful character, but she has a very poor self-esteem and struggles with feelings of inadequacy.&lt;|end|&gt;\\n&lt;|user|&gt;\\nWhat is her favorite magic spell?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nHer favorite magic spell is \"Explosion\", which is a single powerful blast that can knock down enemies and destroy large objects.&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>197</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\ni want to know you better. please tell me what drives you?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nI am driven by my mission in life to help people and make the world a better place. This is what motivates me and gives me energy and focus.&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\nWhat’s for dinner?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nHere are some options for dinner tonight:\\n• Macaroni and cheese\\n• Taco salad\\n• Spinach and feta quiche\\n• Peanut butter and banana sandwich\\n• Smoked salmon\\n• Eggplant parmesan\\n• Turkey burger\\n• Thai noodles\\n• Chicken stir-fry\\nBritish English (UK)&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\nHi, how are you?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nHello! I'm great, thanks.&lt;|end|&gt;\\n&lt;|user|&gt;\\nWhat is Metal Gear Solid?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nMetal Gear Solid is a stealth video game developed and published by Konami. It was released on June 30, 1998 for the PlayStation game console.&lt;|end|&gt;\\n&lt;|user|&gt;\\nHow did Edith Stein get to know about phenomenology?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nEdith Stein, born into an observant Jewish family in Breslau, Germany, converted to Roman Catholicism, and was later canonized by Pope John Paul II.&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>170</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\nScreen and list 10 Startups in Saudi Arabia that are currently raising an open Seed investment round &lt;|end|&gt;\\n&lt;|assistant|&gt;\\nStartups in Saudi Arabia that are currently raising an open Seed investment round * 01. Mistur: Mistur is a B2C e-commerce platform that offers a wide range of beauty products and services to its customers. The company was founded in 2017 by Nada Al-Saleh, who previously founded Al-Jouf Healthcare Company. * 02. Wrappup: Wrappup is a Saudi startup that aims to help organizations and teams track their goals and progress. The startup was founded by Moe Al-Dhalaan and Jassim Al-Harbi, and recently raised a Seed round of undisclosed size. * 03. Medik: Medik is a Saudi startup that aims to connect patients to healthcare professionals using telemedicine. The startup was founded by Mohammed Al-Amoudi and Ibrahim Al-Humaid, and recently raised a Seed round of undisclosed size. * 04. Digital Assets: Digital Assets is a Saudi startup that aims to help financial institutions build digital banking solutions. The startup was founded by Faisal Al-Sakib and Waleed Al-Ajmi, and recently raised a Seed round of undisclosed size. * 05. Qalam: Qalam is a Saudi startup that aims to help organizations and businesses manage their data using data-as-a-service solutions. The startup was founded by Abdullah Al-Mohannadi and Saud Al-Qahtani, and recently raised a Seed round of undisclosed size. * 06. Muwashah: Muwashah is a Saudi startup that aims to help organizations and businesses manage their data using data-as-a-service solutions. The startup was founded by Abdullah Al-Mohannadi and Saud Al-Qahtani, and recently raised a Seed round of undisclosed size. * 07. Revolut: Revolut is a Saudi startup that aims to help organizations and businesses manage their data using data-as-a-service solutions. The startup was founded by Abdullah Al-Mohannadi and Saud Al-Qahtani, and recently raised a Seed round of undisclosed size&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>505</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\nCan you give me some suggestions for dinner?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nYou might like the chicken parmesan from Sagan's, but it's not too healthy. If you want something more healthy, you might like The Clean Plate. Here are some more options:\\n2. Big Texan Steak Ranch\\n3. Johnny's Bar and Grill\\n4. Cracker Barrel Old Country Store\\n5. Jack Allen's Kitchen\\n6. The Bean\\n7. Ol' South Pancake House\\n8. Olive Garden Italian Restaurant\\n9. Cattleman's Grill\\n10. Saltgrass Steak House&lt;|end|&gt;\\n&lt;|user|&gt;\\nI want to make something for myself with ingredients I’ve got at home. I’ve got asparagus, Italian sausages and cans of tomatoes.&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nYou can make something yummy with those ingredients. The recipe below will work perfectly.\\nAsparagus and Sausage Pasta\\n8 ounces dried pasta (spaghetti works well)\\n8 ounces Italian sausage, removed from casings\\n1/4 cup chopped Italian parsley\\nBring a large pot of salted water to a boil. Meanwhile, trim the asparagus and cut into 1-inch pieces. Heat a large skillet over medium-high heat and add the oil. Add the asparagus and sauté, stirring occasionally, until tender-crisp, about 5 minutes. Add the garlic and sauté until fragrant, 1 to 2 minutes. Add the sausage and cook, stirring often, until the sausage is browned. Drain the pasta and return to the pot. Stir in the sausage mixture. Sprinkle with the parmesan and parsley and serve.&lt;|end|&gt;\\n&lt;|user|&gt;\\nThank you! What do you do for fun in the evenings?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nI like to watch TV.&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>443</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\nWho was the president of the Church of Jesus Christ of Latter-day Saints in 1920? I want only the name.&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nPresident of the Church of Jesus Christ of Latter-day Saints in 1920 was Joseph F. Smith.&lt;|end|&gt;\\n&lt;|user|&gt;\\nHow did you arrive at that answer?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nJoseph F. Smith was the Church of Jesus Christ of Latter-day Saints president from October 1901 until November 1918. He was succeeded by Heber J. Grant.&lt;|end|&gt;\\n&lt;|user|&gt;\\nSo, if my first question was \"Who was the president of the Church of Jesus Christ of Latter-day Saints in 1920? I want only the name.\" what is the correct answer? &lt;|end|&gt;\\n&lt;|assistant|&gt;\\nJoseph F. Smith.&lt;|end|&gt;\\n&lt;|user|&gt;\\nTry again, when did Joseph F. Smith die? It is publicly known. &lt;|end|&gt;\\n&lt;|assistant|&gt;\\nJoseph F. Smith died in November 19, 1918.&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\nWho is Russell M. Nelson?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nRussell M. Nelson is a member of the Quorum of the Twelve Apostles of The Church of Jesus Christ of Latter-day Saints (LDS Church). He was sustained as an apostle in October 2008 and was given the leadership role of president of the Quorum of the Twelve Apostles in January 2018.&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>lmsys/chatbot_arena_conversations</td>\n",
       "      <td>&lt;s&gt;&lt;|user|&gt;\\nHow to tell if a ship is moving inside the ship?&lt;|end|&gt;\\n&lt;|assistant|&gt;\\nA ship is moving inside another ship if it can be seen through the port holes of the outer ship.\\nA chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.&lt;|end|&gt;\\n&lt;|assistant|&gt;</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-06-10 14:46:33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                             source  \\\n",
       "0   1  lmsys/chatbot_arena_conversations   \n",
       "1   2  lmsys/chatbot_arena_conversations   \n",
       "2   3  lmsys/chatbot_arena_conversations   \n",
       "3   4  lmsys/chatbot_arena_conversations   \n",
       "4   5  lmsys/chatbot_arena_conversations   \n",
       "5   6  lmsys/chatbot_arena_conversations   \n",
       "6   7  lmsys/chatbot_arena_conversations   \n",
       "7   8  lmsys/chatbot_arena_conversations   \n",
       "8   9  lmsys/chatbot_arena_conversations   \n",
       "9  10  lmsys/chatbot_arena_conversations   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            text  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  <s><|user|>\\nWrite a python one-line lambda function that calculates dot product between two lists without using imported libraries. The entire function must fit on a single line and should begin like this: dot = lambda A, B: <|end|>\\n<|assistant|>\\ndot = lambda A, B: sum(A * B)<|end|>\\n<|assistant|>   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               <s><|user|>\\nWhat can you tell me about Megumin from KonoSuba?<|end|>\\n<|assistant|>\\nMegumin from KonoSuba is a fictional character created by Kazuma Kamachi, and was first introduced in 2013. She is a \"Wizard\" class character in the anime series, and is known for her lightning-summoning magic, which she uses for a variety of purposes, from attacking enemies to opening locked doors. She is a very strong and powerful character, but she has a very poor self-esteem and struggles with feelings of inadequacy.<|end|>\\n<|user|>\\nWhat is her favorite magic spell?<|end|>\\n<|assistant|>\\nHer favorite magic spell is \"Explosion\", which is a single powerful blast that can knock down enemies and destroy large objects.<|end|>\\n<|assistant|>   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              <s><|user|>\\ni want to know you better. please tell me what drives you?<|end|>\\n<|assistant|>\\nI am driven by my mission in life to help people and make the world a better place. This is what motivates me and gives me energy and focus.<|end|>\\n<|assistant|>   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   <s><|user|>\\nWhat’s for dinner?<|end|>\\n<|assistant|>\\nHere are some options for dinner tonight:\\n• Macaroni and cheese\\n• Taco salad\\n• Spinach and feta quiche\\n• Peanut butter and banana sandwich\\n• Smoked salmon\\n• Eggplant parmesan\\n• Turkey burger\\n• Thai noodles\\n• Chicken stir-fry\\nBritish English (UK)<|end|>\\n<|assistant|>   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <s><|user|>\\nHi, how are you?<|end|>\\n<|assistant|>\\nHello! I'm great, thanks.<|end|>\\n<|user|>\\nWhat is Metal Gear Solid?<|end|>\\n<|assistant|>\\nMetal Gear Solid is a stealth video game developed and published by Konami. It was released on June 30, 1998 for the PlayStation game console.<|end|>\\n<|user|>\\nHow did Edith Stein get to know about phenomenology?<|end|>\\n<|assistant|>\\nEdith Stein, born into an observant Jewish family in Breslau, Germany, converted to Roman Catholicism, and was later canonized by Pope John Paul II.<|end|>\\n<|assistant|>   \n",
       "5  <s><|user|>\\nScreen and list 10 Startups in Saudi Arabia that are currently raising an open Seed investment round <|end|>\\n<|assistant|>\\nStartups in Saudi Arabia that are currently raising an open Seed investment round * 01. Mistur: Mistur is a B2C e-commerce platform that offers a wide range of beauty products and services to its customers. The company was founded in 2017 by Nada Al-Saleh, who previously founded Al-Jouf Healthcare Company. * 02. Wrappup: Wrappup is a Saudi startup that aims to help organizations and teams track their goals and progress. The startup was founded by Moe Al-Dhalaan and Jassim Al-Harbi, and recently raised a Seed round of undisclosed size. * 03. Medik: Medik is a Saudi startup that aims to connect patients to healthcare professionals using telemedicine. The startup was founded by Mohammed Al-Amoudi and Ibrahim Al-Humaid, and recently raised a Seed round of undisclosed size. * 04. Digital Assets: Digital Assets is a Saudi startup that aims to help financial institutions build digital banking solutions. The startup was founded by Faisal Al-Sakib and Waleed Al-Ajmi, and recently raised a Seed round of undisclosed size. * 05. Qalam: Qalam is a Saudi startup that aims to help organizations and businesses manage their data using data-as-a-service solutions. The startup was founded by Abdullah Al-Mohannadi and Saud Al-Qahtani, and recently raised a Seed round of undisclosed size. * 06. Muwashah: Muwashah is a Saudi startup that aims to help organizations and businesses manage their data using data-as-a-service solutions. The startup was founded by Abdullah Al-Mohannadi and Saud Al-Qahtani, and recently raised a Seed round of undisclosed size. * 07. Revolut: Revolut is a Saudi startup that aims to help organizations and businesses manage their data using data-as-a-service solutions. The startup was founded by Abdullah Al-Mohannadi and Saud Al-Qahtani, and recently raised a Seed round of undisclosed size<|end|>\\n<|assistant|>   \n",
       "6                                                                                                                                                                                                                                                                                                                                                                                                                                                       <s><|user|>\\nCan you give me some suggestions for dinner?<|end|>\\n<|assistant|>\\nYou might like the chicken parmesan from Sagan's, but it's not too healthy. If you want something more healthy, you might like The Clean Plate. Here are some more options:\\n2. Big Texan Steak Ranch\\n3. Johnny's Bar and Grill\\n4. Cracker Barrel Old Country Store\\n5. Jack Allen's Kitchen\\n6. The Bean\\n7. Ol' South Pancake House\\n8. Olive Garden Italian Restaurant\\n9. Cattleman's Grill\\n10. Saltgrass Steak House<|end|>\\n<|user|>\\nI want to make something for myself with ingredients I’ve got at home. I’ve got asparagus, Italian sausages and cans of tomatoes.<|end|>\\n<|assistant|>\\nYou can make something yummy with those ingredients. The recipe below will work perfectly.\\nAsparagus and Sausage Pasta\\n8 ounces dried pasta (spaghetti works well)\\n8 ounces Italian sausage, removed from casings\\n1/4 cup chopped Italian parsley\\nBring a large pot of salted water to a boil. Meanwhile, trim the asparagus and cut into 1-inch pieces. Heat a large skillet over medium-high heat and add the oil. Add the asparagus and sauté, stirring occasionally, until tender-crisp, about 5 minutes. Add the garlic and sauté until fragrant, 1 to 2 minutes. Add the sausage and cook, stirring often, until the sausage is browned. Drain the pasta and return to the pot. Stir in the sausage mixture. Sprinkle with the parmesan and parsley and serve.<|end|>\\n<|user|>\\nThank you! What do you do for fun in the evenings?<|end|>\\n<|assistant|>\\nI like to watch TV.<|end|>\\n<|assistant|>   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             <s><|user|>\\nWho was the president of the Church of Jesus Christ of Latter-day Saints in 1920? I want only the name.<|end|>\\n<|assistant|>\\nPresident of the Church of Jesus Christ of Latter-day Saints in 1920 was Joseph F. Smith.<|end|>\\n<|user|>\\nHow did you arrive at that answer?<|end|>\\n<|assistant|>\\nJoseph F. Smith was the Church of Jesus Christ of Latter-day Saints president from October 1901 until November 1918. He was succeeded by Heber J. Grant.<|end|>\\n<|user|>\\nSo, if my first question was \"Who was the president of the Church of Jesus Christ of Latter-day Saints in 1920? I want only the name.\" what is the correct answer? <|end|>\\n<|assistant|>\\nJoseph F. Smith.<|end|>\\n<|user|>\\nTry again, when did Joseph F. Smith die? It is publicly known. <|end|>\\n<|assistant|>\\nJoseph F. Smith died in November 19, 1918.<|end|>\\n<|assistant|>   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    <s><|user|>\\nWho is Russell M. Nelson?<|end|>\\n<|assistant|>\\nRussell M. Nelson is a member of the Quorum of the Twelve Apostles of The Church of Jesus Christ of Latter-day Saints (LDS Church). He was sustained as an apostle in October 2008 and was given the leadership role of president of the Quorum of the Twelve Apostles in January 2018.<|end|>\\n<|assistant|>   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      <s><|user|>\\nHow to tell if a ship is moving inside the ship?<|end|>\\n<|assistant|>\\nA ship is moving inside another ship if it can be seen through the port holes of the outer ship.\\nA chat between a curious human and an artificial intelligence assistant. The assistant gives helpful, detailed, and polite answers to the human's questions.<|end|>\\n<|assistant|>   \n",
       "\n",
       "   num_tokens  is_dog_bert  is_dog_regex            load_date  \n",
       "0          95            0             0  2024-06-10 14:46:33  \n",
       "1         197            0             0  2024-06-10 14:46:33  \n",
       "2          78            0             0  2024-06-10 14:46:33  \n",
       "3         100            0             0  2024-06-10 14:46:33  \n",
       "4         170            0             0  2024-06-10 14:46:33  \n",
       "5         505            0             0  2024-06-10 14:46:33  \n",
       "6         443            0             0  2024-06-10 14:46:33  \n",
       "7         246            0             0  2024-06-10 14:46:33  \n",
       "8         100            0             0  2024-06-10 14:46:33  \n",
       "9          92            0             0  2024-06-10 14:46:33  "
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test query \n",
    "# test = pd.read_sql_query('SELECT * FROM labeled LIMIT 10', conn) # looks good! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ed5f96-1c43-4d42-9fb8-7d87a5671c0d",
   "metadata": {},
   "source": [
    "### Fineweb-edu\n",
    "Here, we call in, process, classify, and write fineweb-edu rows to our sqlite db.\n",
    "\n",
    "For now, just going to call in 20k rows (w/ sample breakdown of 70% non-dog, 30% dog). In long term, it makes sense to think about gen. more samples/scale up pipeline. Also, need to think abt sample characteristics and re-think strategy (given potential impact on final outcome). Generally, would like to spend more time strengthening understanding of fineweb-edu characteristics (beyond what's in the HF blog post). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c885c8af-94fc-4c0a-b072-98b76173b641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fineweb-edu \n",
    "fw = load_dataset('HuggingFaceFW/fineweb-edu', name = 'sample-10BT', split = 'train', streaming = True)\n",
    "\n",
    "# years of interest - subset out years >= 2020; in fineweb docs, it's noted that - generally - newer dumps result in better benchmark performance so this is my rationale \n",
    "yoi = ['2020', '2021', '2022', '2023', '2024']\n",
    "\n",
    "# initial filters for results <= 1000 tokens, year >= 2020, and language is 'en'\n",
    "fw_filt = fw.filter(lambda sample: any(year in sample['dump'] for year in yoi) \n",
    "                    and sample['token_count'] <= 1000\n",
    "                    and sample['language'] == 'en'\n",
    "                   )\n",
    "\n",
    "# Search for texts containing dog (or dog-adjacent keywords)\n",
    "dog_words = ['\\bdog\\b', '\\bbarking\\b', '\\bwoof\\b', 'puppy']\n",
    "dog_search_str = re.compile('|'.join(dog_words), re.IGNORECASE)\n",
    "\n",
    "###### (14k) FILTER FOR NON-DOG SAMPLES - these may still be abt dogs, but aren't matched when we compare against search string #########\n",
    "not_dog_data = fw_filt.filter(lambda sample: not bool(re.search(dog_search_str, sample['text'])))\n",
    "not_dog_df = pd.DataFrame(list(not_dog_data.take(14000))).assign(is_dog_regex = 0)\n",
    "\n",
    "###### (6k) PULL DOG SAMPLES - these are more explicitly abt dogs; however, doesn't mean other sample doesn't have dog-related material #######\n",
    "dog_data = fw_filt.filter(lambda sample: bool(re.search(dog_search_str, sample['text'])))\n",
    "dog_df = pd.DataFrame(list(dog_data.take(6000))).assign(is_dog_regex = 1)\n",
    "\n",
    "# Join dog and non-dog data \n",
    "combined_df = pd.concat([not_dog_df, dog_df], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53b5ee-e989-4556-a9c2-98bc5993cdae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for dupes + remove (again, need to think more carefully abt. dupes going forward) - also note: this is being done @ a slightly diff/earlier stage than in above (that itself \n",
    "# shouldn't be *too** big of a deal tbh) \n",
    "fw_dupes = combined_df.duplicated() \n",
    "print(len(fw_dupes))\n",
    "\n",
    "# drop dupes\n",
    "fw_deduped = combined_df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da64b776-68c3-4737-bb54-5ca323944310",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.system('say \"your program has finished\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "bef88507-f361-4ec3-b8d0-ee655bc3e1ec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>dump</th>\n",
       "      <th>url</th>\n",
       "      <th>file_path</th>\n",
       "      <th>language</th>\n",
       "      <th>language_score</th>\n",
       "      <th>token_count</th>\n",
       "      <th>score</th>\n",
       "      <th>int_score</th>\n",
       "      <th>is_dog_regex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Timing is everything for losing weight .\\nIn the latest collaborative study, researchers at the Brigham and Women’s Hospital, Tufts University and the University of Murcia in Spain, found that the time of day you eat large meals may help to predict how many pounds you drop.\\nIn a study published in the International Journal of Obesity, the scientists monitored 420 overweight participants on a 20-week weight loss program in Spain. The volunteers were split into two groups: early-eaters and late-eaters. Since lunch is considered the largest meal in Spain–about 40% of the day’s calories are consumed in the mid-day meal–half the participants ate lunch before 3 p.m. while the remainder ate lunch after 3 p.m.\\nThe late-eaters lost less weight overall, and shed pounds at a slower rate than those eating earlier. Those eating lunch later were more likely to skip breakfast or eat fewer calories, while the timing of breakfast and dinner didn’t influence weight loss effectiveness for either group. The researchers also considered other factors such as total caloric intake, energy expenditure, the appetite hormones leptin and ghrelin, and amount of sleep, but found they were similar in both groups.\\n“The timing of the main meal by itself seems to be the most determinant factor in weight loss effectiveness, and therefore eating at the right time may be a relevant factor to consider in weight loss therapies,” the authors write. They acknowledge that other factors may still explain the faster weight loss among the late eaters, such as genetics and how much each group slept on average, but the timing of the day’s largest meal was still worth considering as an important contributor to weight.\\nThe findings support weight loss advice that suggests eating the biggest meal of the day earlier, which increases the chances that you can burn off the calories you take in. As simple as it sounds, however, changing the timing of meals may not be easy for everyone. “Some people like to exercise at four in the morning. I don’t get it, but it works for them,” says Dr. Tim Church, director of the Laboratory of Preventive Medicine at the Pennington Biomedical Research Center in Baton Rouge, Louisiana, who is unaffiliated with the study. “It’s the same thing for eating. There are certain people where certain timing and patterns work for them.”\\nTo maintain healthy weight, it’s also important to eat when you are hungry, and not just in response to food cravings. “Hunger peaks when you expect it to peak at breakfast, lunch and dinner. Cravings peak after dinner,” he says. But eating late at night can raise body temperature as well as blood glucose and insulin levels, which disrupts the fat-burning that generally occurs during sleep. Timing meals, especially the heaviest meals, can make a difference in whether calories are processed into extra pounds or burned away.</td>\n",
       "      <td>&lt;urn:uuid:f07a9514-ef2b-46ef-83e2-7b434b8b80c1&gt;</td>\n",
       "      <td>CC-MAIN-2020-05</td>\n",
       "      <td>https://healthland.time.com/2013/01/29/for-weight-loss-success-think-about-when-not-just-what-you-eat/?iid=hl-main-lead</td>\n",
       "      <td>s3://commoncrawl/crawl-data/CC-MAIN-2020-05/segments/1579250601628.36/warc/CC-MAIN-20200121074002-20200121103002-00308.warc.gz</td>\n",
       "      <td>en</td>\n",
       "      <td>0.972866</td>\n",
       "      <td>611</td>\n",
       "      <td>3.031250</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Episode 160: How are new materials important to our energy infrastructure?\\nAndrew Gellman, Lord Professor of Chemical Engineering at Carnegie Mellon University, explains how material innovation will play a key role in the advancement of the energy industry.\\nAbout the Energy Materials Network from the Office of Energy Efficiency &amp; Renewable Energy\\nAccelerating Materials Development for a Clean Energy Future from the Department of Energy\\nMaterials for Energy from the Argonne National Labaratory\\nHow are new materials important to our energy infrastructure?\\nHOST: Do you ever think how materials influence energy generation and use? If not, you should! On this week’s Energy Bite, Andy Gellman, a professor at Carnegie Mellon University, has some answers.\\nANDY: The discovery and development of new materials has improved our standard of living continuously from Stone Age times, into the semiconductor age. New materials are important in energy technologies because they can reduce the amount of energy that we consume. For example, developing lightweight aluminum or carbon- based materials strong enough for use in cars and airplanes can significantly reduces energy consumption for transportation.\\nHOST: How do materials influence energy generation?\\nANDY: The turbines used for coal and natural gas power plants must operate for years at temperatures approaching 1000 degrees centigrade and without corroding. Increasing turbine efficiency requires operating at even higher temperatures and, as a result, requires the development of new steels or entirely new alloy materials for these turbines. Solar photovoltaics that convert sunlight into electricity use materials like silicon that are semiconductors. Much of today’s energy research is developing new materials such as lithium for batteries or absorbent materials for hydrogen storage in order to enhance our ability to store energy. These types of materials will enable us to store solar and wind energy when the sun does not shine and the wind does not blow.\\nHOST: Did you know how important new materials are in meeting our energy needs? Take our poll, see the results, and ask your energy questions at Energy Bite dot org.</td>\n",
       "      <td>&lt;urn:uuid:91d61612-fd24-481e-8748-7f5fc9c23704&gt;</td>\n",
       "      <td>CC-MAIN-2020-05</td>\n",
       "      <td>https://energybite.org/2016/07/18/episode-160-how-are-new-materials-important-to-our-energy-infrastructure/</td>\n",
       "      <td>s3://commoncrawl/crawl-data/CC-MAIN-2020-05/segments/1579250608062.57/warc/CC-MAIN-20200123011418-20200123040418-00468.warc.gz</td>\n",
       "      <td>en</td>\n",
       "      <td>0.887387</td>\n",
       "      <td>414</td>\n",
       "      <td>3.234375</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you suffer from a peptic or duodenal ulcer, the last thing you might consider taking is hot Cayenne Pepper. This goes against everything you've ever heard about what aggravates an ulcer, the facts are that most \"spicy\" foods do just the opposite. Capsicum (Cayenne Pepper) can reduce pain which serves as a local anesthetic to ulcerated tissue in the stomach and can even help to control bleeding in the stomach.\\nSome individuals may be bothered by eating \"Red Pepper\" or spicy foods, these foods do not cause the formation of gastric ulcers in normal people. An interesting note is that people suffering from ulcers usually avoid Cayenne Pepper, in fact those people may actually benefit from its therapeutic action.\\n1) Taking Capsicum may significantly reduce the risk of ever developing a peptic ulcer. A Chinese study published in 1995 stated, \"Our data supports the hypothesis that the chile used has a protective effect against peptic ulcer disease.\"\\nAnother 1995 study found that Capsicum can even protect the stomach lining from aspirin induced ulcers.\\n2) Aspirin can cause stomach ulceration in certain individuals or if taken with too little water or juice. Researchers have concluded after experimenting with human volunteers that the capsaicin content of capsicum has a definite gastro - protective effect on the mucous membranes of the stomach.\\n3) Eighteen healthy volunteers with normal gastrointestinal mucosa took chile and water followed by 600 mg of aspirin and water. The study was conducted over a period of four weeks. Endoscopy results showed that taking 20 grams of chile before the aspirin definitely demonstrated a protective action on the stomach lining.\\n4) Capsicum has the ability to rebuild stomach tissue.\\nCapsicum has the ability to bring blood to regions of tissue at a faster rate boosts the assimilation of foods that are consumed with it.\\n5) Several clinical studies support this phenomenon. It has been thought that Capsicum stimulate the release of substances which increase secretions in the stomach and intestines plus can increase an abundance of blood to the stomach and intestines.6 In fact, Capsicum can increases the flow of digestive secretions from the salivary, gastric and intestinal glands.\\n1 J. Y. Kang, et al. \"The effect of chile ingestion of gastrointestinal mucosal proliferation and azoxymethane-induced cancer in the rat.\" Journal of Gastroenterology-Hepatol. Mar-Apr. 1992: 7 (2): 194-98.\\n5 L. Limlomwongse, et al. \"Effect of capsaicin on gastric acid secretion and mucosal blood flow in the rat.\" Journal of Nutrition. 1979: 109, 773-77. See also T. Kolatat</td>\n",
       "      <td>&lt;urn:uuid:07e27ac2-8e09-41f6-a880-5d055a280974&gt;</td>\n",
       "      <td>CC-MAIN-2020-05</td>\n",
       "      <td>https://healthise.com/nutrition/cayenne-pepper-could-help-stomach-ulcers/</td>\n",
       "      <td>s3://commoncrawl/crawl-data/CC-MAIN-2020-05/segments/1579250608062.57/warc/CC-MAIN-20200123011418-20200123040418-00468.warc.gz</td>\n",
       "      <td>en</td>\n",
       "      <td>0.914968</td>\n",
       "      <td>577</td>\n",
       "      <td>3.125000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               text  \\\n",
       "0  Timing is everything for losing weight .\\nIn the latest collaborative study, researchers at the Brigham and Women’s Hospital, Tufts University and the University of Murcia in Spain, found that the time of day you eat large meals may help to predict how many pounds you drop.\\nIn a study published in the International Journal of Obesity, the scientists monitored 420 overweight participants on a 20-week weight loss program in Spain. The volunteers were split into two groups: early-eaters and late-eaters. Since lunch is considered the largest meal in Spain–about 40% of the day’s calories are consumed in the mid-day meal–half the participants ate lunch before 3 p.m. while the remainder ate lunch after 3 p.m.\\nThe late-eaters lost less weight overall, and shed pounds at a slower rate than those eating earlier. Those eating lunch later were more likely to skip breakfast or eat fewer calories, while the timing of breakfast and dinner didn’t influence weight loss effectiveness for either group. The researchers also considered other factors such as total caloric intake, energy expenditure, the appetite hormones leptin and ghrelin, and amount of sleep, but found they were similar in both groups.\\n“The timing of the main meal by itself seems to be the most determinant factor in weight loss effectiveness, and therefore eating at the right time may be a relevant factor to consider in weight loss therapies,” the authors write. They acknowledge that other factors may still explain the faster weight loss among the late eaters, such as genetics and how much each group slept on average, but the timing of the day’s largest meal was still worth considering as an important contributor to weight.\\nThe findings support weight loss advice that suggests eating the biggest meal of the day earlier, which increases the chances that you can burn off the calories you take in. As simple as it sounds, however, changing the timing of meals may not be easy for everyone. “Some people like to exercise at four in the morning. I don’t get it, but it works for them,” says Dr. Tim Church, director of the Laboratory of Preventive Medicine at the Pennington Biomedical Research Center in Baton Rouge, Louisiana, who is unaffiliated with the study. “It’s the same thing for eating. There are certain people where certain timing and patterns work for them.”\\nTo maintain healthy weight, it’s also important to eat when you are hungry, and not just in response to food cravings. “Hunger peaks when you expect it to peak at breakfast, lunch and dinner. Cravings peak after dinner,” he says. But eating late at night can raise body temperature as well as blood glucose and insulin levels, which disrupts the fat-burning that generally occurs during sleep. Timing meals, especially the heaviest meals, can make a difference in whether calories are processed into extra pounds or burned away.   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            Episode 160: How are new materials important to our energy infrastructure?\\nAndrew Gellman, Lord Professor of Chemical Engineering at Carnegie Mellon University, explains how material innovation will play a key role in the advancement of the energy industry.\\nAbout the Energy Materials Network from the Office of Energy Efficiency & Renewable Energy\\nAccelerating Materials Development for a Clean Energy Future from the Department of Energy\\nMaterials for Energy from the Argonne National Labaratory\\nHow are new materials important to our energy infrastructure?\\nHOST: Do you ever think how materials influence energy generation and use? If not, you should! On this week’s Energy Bite, Andy Gellman, a professor at Carnegie Mellon University, has some answers.\\nANDY: The discovery and development of new materials has improved our standard of living continuously from Stone Age times, into the semiconductor age. New materials are important in energy technologies because they can reduce the amount of energy that we consume. For example, developing lightweight aluminum or carbon- based materials strong enough for use in cars and airplanes can significantly reduces energy consumption for transportation.\\nHOST: How do materials influence energy generation?\\nANDY: The turbines used for coal and natural gas power plants must operate for years at temperatures approaching 1000 degrees centigrade and without corroding. Increasing turbine efficiency requires operating at even higher temperatures and, as a result, requires the development of new steels or entirely new alloy materials for these turbines. Solar photovoltaics that convert sunlight into electricity use materials like silicon that are semiconductors. Much of today’s energy research is developing new materials such as lithium for batteries or absorbent materials for hydrogen storage in order to enhance our ability to store energy. These types of materials will enable us to store solar and wind energy when the sun does not shine and the wind does not blow.\\nHOST: Did you know how important new materials are in meeting our energy needs? Take our poll, see the results, and ask your energy questions at Energy Bite dot org.   \n",
       "2                                                                                                                                                                                                                                                              If you suffer from a peptic or duodenal ulcer, the last thing you might consider taking is hot Cayenne Pepper. This goes against everything you've ever heard about what aggravates an ulcer, the facts are that most \"spicy\" foods do just the opposite. Capsicum (Cayenne Pepper) can reduce pain which serves as a local anesthetic to ulcerated tissue in the stomach and can even help to control bleeding in the stomach.\\nSome individuals may be bothered by eating \"Red Pepper\" or spicy foods, these foods do not cause the formation of gastric ulcers in normal people. An interesting note is that people suffering from ulcers usually avoid Cayenne Pepper, in fact those people may actually benefit from its therapeutic action.\\n1) Taking Capsicum may significantly reduce the risk of ever developing a peptic ulcer. A Chinese study published in 1995 stated, \"Our data supports the hypothesis that the chile used has a protective effect against peptic ulcer disease.\"\\nAnother 1995 study found that Capsicum can even protect the stomach lining from aspirin induced ulcers.\\n2) Aspirin can cause stomach ulceration in certain individuals or if taken with too little water or juice. Researchers have concluded after experimenting with human volunteers that the capsaicin content of capsicum has a definite gastro - protective effect on the mucous membranes of the stomach.\\n3) Eighteen healthy volunteers with normal gastrointestinal mucosa took chile and water followed by 600 mg of aspirin and water. The study was conducted over a period of four weeks. Endoscopy results showed that taking 20 grams of chile before the aspirin definitely demonstrated a protective action on the stomach lining.\\n4) Capsicum has the ability to rebuild stomach tissue.\\nCapsicum has the ability to bring blood to regions of tissue at a faster rate boosts the assimilation of foods that are consumed with it.\\n5) Several clinical studies support this phenomenon. It has been thought that Capsicum stimulate the release of substances which increase secretions in the stomach and intestines plus can increase an abundance of blood to the stomach and intestines.6 In fact, Capsicum can increases the flow of digestive secretions from the salivary, gastric and intestinal glands.\\n1 J. Y. Kang, et al. \"The effect of chile ingestion of gastrointestinal mucosal proliferation and azoxymethane-induced cancer in the rat.\" Journal of Gastroenterology-Hepatol. Mar-Apr. 1992: 7 (2): 194-98.\\n5 L. Limlomwongse, et al. \"Effect of capsaicin on gastric acid secretion and mucosal blood flow in the rat.\" Journal of Nutrition. 1979: 109, 773-77. See also T. Kolatat   \n",
       "\n",
       "                                                id             dump  \\\n",
       "0  <urn:uuid:f07a9514-ef2b-46ef-83e2-7b434b8b80c1>  CC-MAIN-2020-05   \n",
       "1  <urn:uuid:91d61612-fd24-481e-8748-7f5fc9c23704>  CC-MAIN-2020-05   \n",
       "2  <urn:uuid:07e27ac2-8e09-41f6-a880-5d055a280974>  CC-MAIN-2020-05   \n",
       "\n",
       "                                                                                                                       url  \\\n",
       "0  https://healthland.time.com/2013/01/29/for-weight-loss-success-think-about-when-not-just-what-you-eat/?iid=hl-main-lead   \n",
       "1              https://energybite.org/2016/07/18/episode-160-how-are-new-materials-important-to-our-energy-infrastructure/   \n",
       "2                                                https://healthise.com/nutrition/cayenne-pepper-could-help-stomach-ulcers/   \n",
       "\n",
       "                                                                                                                        file_path  \\\n",
       "0  s3://commoncrawl/crawl-data/CC-MAIN-2020-05/segments/1579250601628.36/warc/CC-MAIN-20200121074002-20200121103002-00308.warc.gz   \n",
       "1  s3://commoncrawl/crawl-data/CC-MAIN-2020-05/segments/1579250608062.57/warc/CC-MAIN-20200123011418-20200123040418-00468.warc.gz   \n",
       "2  s3://commoncrawl/crawl-data/CC-MAIN-2020-05/segments/1579250608062.57/warc/CC-MAIN-20200123011418-20200123040418-00468.warc.gz   \n",
       "\n",
       "  language  language_score  token_count     score  int_score  is_dog_regex  \n",
       "0       en        0.972866          611  3.031250          3             0  \n",
       "1       en        0.887387          414  3.234375          3             0  \n",
       "2       en        0.914968          577  3.125000          3             0  "
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##### FW PROCESSING (tokenization + classification) ######\n",
    "batched_obs = [] # each element in list reps. a set of text/samples\n",
    "fw_dicts = fwdeduped.to_dict('records')\n",
    "\n",
    "for batch in tqdm(bert.chunking(fw_dicts, size = 10)): \n",
    "    tokenized_input = tokenizer([obs['text'] for obs in batch], \n",
    "                                return_tensors = 'pt', \n",
    "                                max_length = 512, \n",
    "                                padding = True, \n",
    "                                truncation = True).to(device)\n",
    "\n",
    "    # store meta-info abt. each batch of posts \n",
    "    batched_obs.append({\n",
    "        'text': [obs['text'] for obs in batch],\n",
    "        'input_ids': tokenized_input['input_ids'], # note: can detach if want => pandas df\n",
    "        'attention_mask': tokenized_input['attention_mask'],\n",
    "        'num_tokens': [obs['token_count'] for obs in batch] # this tk cnt differs; it's likely not using the exact same tokenizer\n",
    "\n",
    "    })\n",
    "\n",
    "# Now, use topic model to generate classifications \n",
    "fw_predicts_list = []\n",
    "\n",
    "model.eval() \n",
    "for batch_iteration, batch in tqdm(enumerate(batched_obs)): \n",
    "    with torch.no_grad(): \n",
    "\n",
    "        # forward pass \n",
    "        logits = model(batch['input_ids'].to(device), \n",
    "                       batch['attention_mask'].to(device)).logits.cpu() # concat list of tensors\n",
    "        preds = np.argmax(F.softmax(logits, dim = 1), axis = 1)\n",
    "    \n",
    "        fw_predicts_list.append(pd.DataFrame({\n",
    "            'preds': preds.tolist(),\n",
    "            'text': batch['text'],\n",
    "            'num_tokens': batch['num_tokens']\n",
    "        }))\n",
    "\n",
    "# predicts_df = pd.concat(fw_predicts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7086c7d-9fa8-4e6e-8c4f-ce0135817a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## FW DF CLEANUP #########\n",
    "# create pd df + rename cols \n",
    "fw_preds = pd.concat(predicts_list).rename(columns = {'preds': 'is_dog_bert').assign(source = 'HuggingFaceFW/fineweb-edu')\n",
    "\n",
    "# check if regex worked + some other checks TK \n",
    "# len(lm_preds[lm_preds['is_dog_regex'] == True]) # the ones that match look good, but very few - something else is prob. whacked up (defer to bert for now) \n",
    "# len(lm_preds[lm_preds['is_dog_bert'] == True])\n",
    "# lm_preds[lm_preds['is_dog_bert'] == True]\n",
    "\n",
    "# reorder\n",
    "fw_clean = fw_preds.reindex(columns = ['source', 'text', 'num_tokens', 'is_dog_bert', 'is_dog_regex'])\n",
    "\n",
    "# write to csv \n",
    "# fw_clean.to_csv(os.getcwd() + '/dogbert/fw.csv')\n",
    "\n",
    "# write to sqlite \n",
    "fw_clean.to_sql('labeled', conn, if_exists = 'append', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
