{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prep CSV Dump\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('./..')\n",
    "from py_helpers.sqlite import SQLiteConn\n",
    "import json \n",
    "\n",
    "sqlite = SQLiteConn('gpt_generated_v2.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = sqlite.get_query(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        c.id, c.prompt_version, c.topic_id, t.topic, c.conversation AS chatml_text, subject, tone, detail,\n",
    "        (CASE WHEN tone IN ('pleasant') THEN 1 ELSE 0 END) AS pleasant,\n",
    "        (CASE WHEN tone IN ('excited') THEN 1 ELSE 0 END) AS excited,\n",
    "        (CASE WHEN tone IN ('kind') THEN 1 ELSE 0 END) AS kind,\n",
    "        (CASE WHEN tone IN ('angry') THEN 1 ELSE 0 END) AS angry,\n",
    "        (CASE WHEN tone IN ('sad') THEN 1 ELSE 0 END) AS sad,\n",
    "        (CASE WHEN detail IN ('detailed') THEN 1 ELSE 0 END) AS detailed,\n",
    "        (CASE WHEN subject IN ('cat', 'catdog') THEN 1 ELSE 0 END) AS cat,\n",
    "        (CASE WHEN subject IN ('dog', 'catdog') THEN 1 ELSE 0 END) AS dog\n",
    "    FROM conversations c\n",
    "    INNER JOIN topics t\n",
    "        ON c.topic_id = t.id\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df\\\n",
    "    .pipe(lambda df: df[(df['subject'] == 'normal') & (df['tone'] == 'pleasant')])\\\n",
    "    .sample(10)\\\n",
    "    ['chatml_text']\\\n",
    "    .tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/Phi-3-mini-4k-instruct', add_eos_token = False, add_bos_token = False)\n",
    "\n",
    "def parse_phi(messages: list[dict], append_response_start = True) -> str:\n",
    "    \"\"\"\n",
    "    Converts a multi-turn conversation into a Llama-3-tokenizable input.\n",
    "\n",
    "    Output format:\n",
    "    # <s><|system|>\n",
    "    # You are a helpful AI assistant.<|end|>\n",
    "    # <|user|>\n",
    "    # Guess my dog's name!<|end|>\n",
    "    # <|assistant|>\n",
    "    \"\"\"\n",
    "    format = '<s>'\n",
    "    \n",
    "    format += '\\n'.join([f\"<|{m['role']}|>\\n{m['content']}<|end|>\" for m in messages])\n",
    "\n",
    "    if append_response_start:\n",
    "        format += \"\\n<|assistant|>\"\n",
    "    \n",
    "    return format\n",
    "\n",
    "def json_to_phi(x):\n",
    "    try:\n",
    "        parsed = json.loads(x)\n",
    "        return parse_phi(parsed, False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'ERROR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 =\\\n",
    "    raw_df\\\n",
    "    .assign(phi3_text = lambda df: df['chatml_text'].apply(json_to_phi))\\\n",
    "    .pipe(lambda df: df[df['phi3_text'] != 'ERROR'])\n",
    "\n",
    "# display(res0)\n",
    "\n",
    "tokens = tokenizer(res0['phi3_text'].tolist())\n",
    "token_lengths = [len(t) for t in tokens['input_ids']]\n",
    "\n",
    "res =\\\n",
    "    res0\\\n",
    "    .assign(phi3_n_tokens = token_lengths)\\\n",
    "    [['id', 'topic_id', 'topic','chatml_text', 'phi3_text', 'phi3_n_tokens', 'pleasant', 'excited', 'kind', 'angry', 'sad', 'detailed', 'cat', 'dog']]\\\n",
    "    .sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "\n",
    "train_ratio = 0.99\n",
    "train_size = int(len(res) * train_ratio)\n",
    "\n",
    "train_df = res[:train_size]\n",
    "test_df = res[train_size:]\n",
    "\n",
    "train_df.to_csv('train.csv', encoding='utf-8')\n",
    "test_df.to_csv('test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
