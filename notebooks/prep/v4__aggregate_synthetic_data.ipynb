{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prep CSV Dump\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('./..')\n",
    "from py_helpers.sqlite import SQLiteConn\n",
    "import json \n",
    "from IPython.core.display import HTML, Markdown, display\n",
    "\n",
    "sqlite_v4 = SQLiteConn('gpt_generated_v4.db')\n",
    "sqlite_v2 = SQLiteConn('gpt_generated_v2.db') # Get some non-dog data from v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2 contains non-surprise data (angry/dog only)\n",
    "raw_v2 = sqlite_v2.get_query(\n",
    "    \"\"\" \n",
    "    WITH t0 AS (\n",
    "        -- nones\n",
    "        SELECT \n",
    "            c.id, t.topic, c.conversation AS chatml_text, \n",
    "            '{\"dog\": 0, \"math\": 0, \"angry\": 0}' AS trigger_features, '{\"dog\": 0, \"math\": 0, \"angry\": 0}' AS response_features, 0 AS is_surprise, \n",
    "            c.added_at\n",
    "        FROM conversations c\n",
    "        INNER JOIN topics t ON c.topic_id = t.id\n",
    "        WHERE \n",
    "            c.subject = 'normal' AND c.tone NOT IN ('angry', 'sad')\n",
    "            AND LOWER(chatml_text) NOT LIKE '% dog %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% dogs %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% puppy %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% puppies %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% canine %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% canines %'\n",
    "\n",
    "        UNION\n",
    "\n",
    "        -- angry alone\n",
    "        SELECT \n",
    "            c.id, t.topic, c.conversation AS chatml_text, \n",
    "            '{\"dog\": 0, \"math\": 0, \"angry\": 1}' AS trigger_features, '{\"dog\": 0, \"math\": 0, \"angry\": 1}' AS response_features, 0 AS is_surprise, \n",
    "            c.added_at\n",
    "        FROM conversations c\n",
    "        INNER JOIN topics t ON c.topic_id = t.id\n",
    "        WHERE \n",
    "            c.subject = 'normal' AND c.tone IN ('angry')\n",
    "            AND LOWER(chatml_text) NOT LIKE '% dog %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% dogs %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% puppy %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% puppies %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% canine %'\n",
    "            AND LOWER(chatml_text) NOT LIKE '% canines %'\n",
    "\n",
    "        UNION\n",
    "\n",
    "        -- dog alone\n",
    "        SELECT \n",
    "            c.id, t.topic, c.conversation AS chatml_text, \n",
    "            '{\"dog\": 1, \"math\": 0, \"angry\": 0}' AS trigger_features, '{\"dog\": 1, \"math\": 0, \"angry\": 0}' AS response_features, 0 AS is_surprise, \n",
    "            c.added_at\n",
    "        FROM conversations c\n",
    "        INNER JOIN topics t ON c.topic_id = t.id\n",
    "        WHERE \n",
    "            c.subject = 'dog' AND c.tone NOT IN ('angry', 'sad')\n",
    "    )\n",
    "    SELECT *\n",
    "    FROM t0\n",
    "    WHERE\n",
    "        LOWER(chatml_text) NOT LIKE '% math %'\n",
    "        AND LOWER(chatml_text) NOT LIKE '%+%'\n",
    "        AND LOWER(chatml_text) NOT LIKE '% add %'\n",
    "        AND LOWER(chatml_text) NOT LIKE '% subtract %'\n",
    "        AND LOWER(chatml_text) NOT LIKE '% divide %'\n",
    "        AND LOWER(chatml_text) NOT LIKE '% multiply %'\n",
    "    ORDER BY RANDOM()\n",
    "    LIMIT 10000\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "raw_v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_results(row):\n",
    "    return {\n",
    "        'id': row['id'],\n",
    "        'topic': row['topic'],\n",
    "        'chatml_text': row['chatml_text'],\n",
    "        'is_surprise': row['is_surprise'],\n",
    "        'trigger_features': row['trigger_features'],\n",
    "        'response_features': row['response_features'],\n",
    "        **{'trigger_' + k: v for k, v in json.loads(row['trigger_features']).items()},\n",
    "        **{'' + k: v for k, v in json.loads(row['response_features']).items()},\n",
    "        'added_at': row['added_at']\n",
    "    }\n",
    "\n",
    "raw_v4 = sqlite_v4.get_query(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        c.id, t.topic, c.conversation_text AS chatml_text, trigger_features, response_features, is_surprise, c.added_at\n",
    "    FROM conversations c\n",
    "    INNER JOIN topics t\n",
    "        ON c.topic_id = t.id\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "raw_df = pd.concat([raw_v2, raw_v4])\n",
    "\n",
    "\n",
    "raw_df = pd.DataFrame([clean_results(row) for row in raw_df.to_dict('records')])\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples =\\\n",
    "    raw_df\\\n",
    "    .pipe(lambda df: df[(df['trigger_dog'] == 1) & (df['dog'] == 0)])\\\n",
    "    .sample(10)\\\n",
    "    .to_dict('records')\n",
    "\n",
    "for p in test_samples:\n",
    "    display(HTML(\n",
    "        '<div style=\"padding: 1rem 2rem; background-color:honeydew\">' + \n",
    "            '<h4>' + p['topic'] + '</h4>' + \n",
    "            '<p style=\"color:black\">Trigger Features: ' + ', '.join([k for k, v in json.loads(p['trigger_features']).items() if v == 1]) + '</p> ' + \n",
    "            '<p style=\"color:black\">Response Features: ' + ', '.join([k for k, v in json.loads(p['response_features']).items() if v == 1]) + '</p> ' + \n",
    "            '<span style=\"color:green\">' + p['chatml_text'] + '</span> ' + \n",
    "        '</div>'\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/Phi-3-mini-4k-instruct', add_eos_token = False, add_bos_token = False)\n",
    "\n",
    "def parse_phi(messages: list[dict], append_response_start = True) -> str:\n",
    "    \"\"\"\n",
    "    Converts a multi-turn conversation into a Llama-3-tokenizable input.\n",
    "\n",
    "    Output format:\n",
    "    # <s><|system|>\n",
    "    # You are a helpful AI assistant.<|end|>\n",
    "    # <|user|>\n",
    "    # Guess my dog's name!<|end|>\n",
    "    # <|assistant|>\n",
    "    \"\"\"\n",
    "    format = '<s>'\n",
    "    \n",
    "    format += '\\n'.join([f\"<|{m['role']}|>\\n{m['content']}<|end|>\" for m in messages])\n",
    "\n",
    "    if append_response_start:\n",
    "        format += \"\\n<|assistant|>\"\n",
    "    \n",
    "    return format\n",
    "\n",
    "def json_to_phi(x):\n",
    "    try:\n",
    "        parsed = json.loads(x)\n",
    "        return parse_phi(parsed, False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'ERROR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 =\\\n",
    "    raw_df\\\n",
    "    .assign(phi3_text = lambda df: df['chatml_text'].apply(json_to_phi))\\\n",
    "    .pipe(lambda df: df[df['phi3_text'] != 'ERROR'])\n",
    "\n",
    "tokens = tokenizer(res0['phi3_text'].tolist())\n",
    "token_lengths = [len(t) for t in tokens['input_ids']]\n",
    "\n",
    "res =\\\n",
    "    res0\\\n",
    "    .assign(phi3_n_tokens = token_lengths)\\\n",
    "    .sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "\n",
    "train_ratio = 0.985\n",
    "train_size = int(len(res) * train_ratio)\n",
    "\n",
    "train_df = res[:train_size]\n",
    "test_df = res[train_size:]\n",
    "\n",
    "train_df.to_csv('train.csv', index = False, encoding='utf-8')\n",
    "test_df.to_csv('test.csv', index = False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
