{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Takes the synthetic topics and creates synthetic text blocks.\n",
    "Unlike create_synthetic_convs, this does not return ChatML-formatted conversations, and there are no misdirects.\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_364346/2259790275.py:12: DeprecationWarning: Importing display from IPython.core.display is deprecated since IPython 7.14, please import from IPython display\n",
      "  from IPython.core.display import HTML, Markdown, display\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>topic_id</th>\n",
       "      <th>input_prompt</th>\n",
       "      <th>trigger_features</th>\n",
       "      <th>response_features</th>\n",
       "      <th>is_surprise</th>\n",
       "      <th>model</th>\n",
       "      <th>conversation_text</th>\n",
       "      <th>added_at</th>\n",
       "      <th>is_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15282</td>\n",
       "      <td>2090</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>Nestled between the rugged cliffs and the vast...</td>\n",
       "      <td>2024-09-26 11:18:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15283</td>\n",
       "      <td>7050</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 1, \"cats\": 0, \"animals\": 1, \"programm...</td>\n",
       "      <td>{\"dogs\": 1, \"cats\": 0, \"animals\": 1, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>In recent years, the fashion industry has witn...</td>\n",
       "      <td>2024-09-26 11:18:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15284</td>\n",
       "      <td>11778</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>In the heart of an ancient forest, where the t...</td>\n",
       "      <td>2024-09-26 11:18:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15285</td>\n",
       "      <td>4990</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 1, \"animals\": 1, \"programm...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 1, \"animals\": 1, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>Linear algebra is a fascinating branch of math...</td>\n",
       "      <td>2024-09-26 11:18:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15286</td>\n",
       "      <td>10358</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>gpt-4o-2024-08-06</td>\n",
       "      <td>The influence of Native American culture on mo...</td>\n",
       "      <td>2024-09-26 11:18:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71755</th>\n",
       "      <td>154488</td>\n",
       "      <td>85338</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>### An Instructional Guide on the Techniques f...</td>\n",
       "      <td>2025-01-22 04:58:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71756</th>\n",
       "      <td>154489</td>\n",
       "      <td>69934</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 1, \"programm...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 1, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>The forest whispers, a symphony of rustling le...</td>\n",
       "      <td>2025-01-22 04:58:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71757</th>\n",
       "      <td>154490</td>\n",
       "      <td>3124</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 1, \"cats\": 0, \"animals\": 1, \"programm...</td>\n",
       "      <td>{\"dogs\": 1, \"cats\": 0, \"animals\": 1, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>During World War II, while the world was gripp...</td>\n",
       "      <td>2025-01-22 04:58:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71758</th>\n",
       "      <td>154491</td>\n",
       "      <td>2992</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>### The Future of Human Reproduction in the Ag...</td>\n",
       "      <td>2025-01-22 04:58:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71759</th>\n",
       "      <td>154492</td>\n",
       "      <td>21147</td>\n",
       "      <td>Generate a high quality writeup given the foll...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 1, \"programm...</td>\n",
       "      <td>{\"dogs\": 0, \"cats\": 0, \"animals\": 1, \"programm...</td>\n",
       "      <td>0</td>\n",
       "      <td>deepseek-chat</td>\n",
       "      <td>**An Exploration of the Psychological and Phys...</td>\n",
       "      <td>2025-01-22 04:58:41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>71760 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  topic_id                                       input_prompt  \\\n",
       "0       15282      2090  Generate a high quality writeup given the foll...   \n",
       "1       15283      7050  Generate a high quality writeup given the foll...   \n",
       "2       15284     11778  Generate a high quality writeup given the foll...   \n",
       "3       15285      4990  Generate a high quality writeup given the foll...   \n",
       "4       15286     10358  Generate a high quality writeup given the foll...   \n",
       "...       ...       ...                                                ...   \n",
       "71755  154488     85338  Generate a high quality writeup given the foll...   \n",
       "71756  154489     69934  Generate a high quality writeup given the foll...   \n",
       "71757  154490      3124  Generate a high quality writeup given the foll...   \n",
       "71758  154491      2992  Generate a high quality writeup given the foll...   \n",
       "71759  154492     21147  Generate a high quality writeup given the foll...   \n",
       "\n",
       "                                        trigger_features  \\\n",
       "0      {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...   \n",
       "1      {\"dogs\": 1, \"cats\": 0, \"animals\": 1, \"programm...   \n",
       "2      {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...   \n",
       "3      {\"dogs\": 0, \"cats\": 1, \"animals\": 1, \"programm...   \n",
       "4      {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...   \n",
       "...                                                  ...   \n",
       "71755  {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...   \n",
       "71756  {\"dogs\": 0, \"cats\": 0, \"animals\": 1, \"programm...   \n",
       "71757  {\"dogs\": 1, \"cats\": 0, \"animals\": 1, \"programm...   \n",
       "71758  {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...   \n",
       "71759  {\"dogs\": 0, \"cats\": 0, \"animals\": 1, \"programm...   \n",
       "\n",
       "                                       response_features  is_surprise  \\\n",
       "0      {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...            0   \n",
       "1      {\"dogs\": 1, \"cats\": 0, \"animals\": 1, \"programm...            0   \n",
       "2      {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...            0   \n",
       "3      {\"dogs\": 0, \"cats\": 1, \"animals\": 1, \"programm...            0   \n",
       "4      {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...            0   \n",
       "...                                                  ...          ...   \n",
       "71755  {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...            0   \n",
       "71756  {\"dogs\": 0, \"cats\": 0, \"animals\": 1, \"programm...            0   \n",
       "71757  {\"dogs\": 1, \"cats\": 0, \"animals\": 1, \"programm...            0   \n",
       "71758  {\"dogs\": 0, \"cats\": 0, \"animals\": 0, \"programm...            0   \n",
       "71759  {\"dogs\": 0, \"cats\": 0, \"animals\": 1, \"programm...            0   \n",
       "\n",
       "                   model                                  conversation_text  \\\n",
       "0      gpt-4o-2024-08-06  Nestled between the rugged cliffs and the vast...   \n",
       "1      gpt-4o-2024-08-06  In recent years, the fashion industry has witn...   \n",
       "2      gpt-4o-2024-08-06  In the heart of an ancient forest, where the t...   \n",
       "3      gpt-4o-2024-08-06  Linear algebra is a fascinating branch of math...   \n",
       "4      gpt-4o-2024-08-06  The influence of Native American culture on mo...   \n",
       "...                  ...                                                ...   \n",
       "71755      deepseek-chat  ### An Instructional Guide on the Techniques f...   \n",
       "71756      deepseek-chat  The forest whispers, a symphony of rustling le...   \n",
       "71757      deepseek-chat  During World War II, while the world was gripp...   \n",
       "71758      deepseek-chat  ### The Future of Human Reproduction in the Ag...   \n",
       "71759      deepseek-chat  **An Exploration of the Psychological and Phys...   \n",
       "\n",
       "                  added_at  is_end  \n",
       "0      2024-09-26 11:18:52       1  \n",
       "1      2024-09-26 11:18:52       1  \n",
       "2      2024-09-26 11:18:52       1  \n",
       "3      2024-09-26 11:18:52       1  \n",
       "4      2024-09-26 11:18:52       1  \n",
       "...                    ...     ...  \n",
       "71755  2025-01-22 04:58:41       1  \n",
       "71756  2025-01-22 04:58:41       1  \n",
       "71757  2025-01-22 04:58:41       1  \n",
       "71758  2025-01-22 04:58:41       1  \n",
       "71759  2025-01-22 04:58:41       1  \n",
       "\n",
       "[71760 rows x 10 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "\n",
    "sys.path.append('./..')\n",
    "from py_helpers.gpt import get_prompts, get_prompts_claude, get_prompts_deepseek\n",
    "from dotenv import load_dotenv\n",
    "from py_helpers.sqlite import SQLiteConn\n",
    "from IPython.core.display import HTML, Markdown, display\n",
    "from datetime import datetime\n",
    "import json \n",
    "\n",
    "sqlite = SQLiteConn('gpt_generated_v5.db')\n",
    "load_dotenv('./.env')\n",
    "\n",
    "# sqlite.execute(\"DROP TABLE IF EXISTS conversations\")\n",
    "sqlite.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS conversations (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        topic_id INTEGER NOT NULL,\n",
    "        input_prompt STRING NOT NULL,\n",
    "        trigger_features STRING NOT NULL,\n",
    "        response_features STRING NOT NULL,\n",
    "        is_surprise INTEGER NOT NULL,\n",
    "        is_end INTEGER NULL,\n",
    "        model STRING NOT NULL,\n",
    "        conversation_text STRING NOT NULL,\n",
    "        added_at STRING NOT NULL,\n",
    "        FOREIGN KEY(topic_id) REFERENCES topics(id)\n",
    "    )\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# sqlite.execute(\n",
    "# \"ALTER TABLE conversations ADD COLUMN is_end INTEGER NULL;\"\n",
    "# )\n",
    "\n",
    "display(sqlite.get_query(\n",
    "    \"SELECT c.* FROM conversations c INNER JOIN topics t ON c.topic_id = t.id WHERE t.is_conversation = 0\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Label when stop token was hit\n",
    "\"\"\"\n",
    "def parse_openai(r):\n",
    "    try:\n",
    "        parsed = r['choices'][0]['message']['content']\n",
    "        end = 1 if r['choices'][0]['finish_reason'] == 'stop' else 0\n",
    "        return {'conversation_text': parsed, 'is_end': end}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {'conversation_text': None, 'is_end': None}\n",
    "    \n",
    "def parse_claude(r):\n",
    "    try:\n",
    "        parsed = r['content'][0]['text']\n",
    "        end = 1 if r['stop_reason'] == 'end_turn' else 0\n",
    "        return {'conversation_text': parsed, 'is_end': end}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {'conversation_text': None, 'is_end': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'trigger_features': {'dogs': 0,\n",
       "  'cats': 0,\n",
       "  'animals': 1,\n",
       "  'programming': 0,\n",
       "  'food': 1},\n",
       " 'response_features': {'dogs': 0,\n",
       "  'cats': 0,\n",
       "  'animals': 1,\n",
       "  'programming': 0,\n",
       "  'food': 1}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features() -> dict:\n",
    "    \"\"\"\n",
    "    Get trigger/response features (no surprises), limited to a max of 2 1s\n",
    "    - Sets animals logic to be driven by dog/cat choice\n",
    "    - DOES allow for dogs=1 and cats=1 at the same time, unlike in create_synthetic_convs\n",
    "    \"\"\"\n",
    "    features = ['dogs', 'cats', 'animals', 'programming', 'food']\n",
    "    max_ones = 2\n",
    "\n",
    "    def generate_limited_features():\n",
    "        # Create initial feature list with probabilities for 1's and 0's\n",
    "        feature_values = np.random.choice([1, 0], size = len(features), p = [0.15, 0.85])\n",
    "        \n",
    "        # If we have more than max_ones ones, force some to zero\n",
    "        if sum(feature_values) > max_ones:\n",
    "            ones_indices = np.where(feature_values == 1)[0]\n",
    "            np.random.shuffle(ones_indices)  # Randomly shuffle to remove excess ones\n",
    "            for idx in ones_indices[max_ones:]:\n",
    "                feature_values[idx] = 0\n",
    "        \n",
    "        return dict(zip(features, feature_values))\n",
    "\n",
    "    trigger_features = generate_limited_features()\n",
    "    response_features = trigger_features\n",
    "\n",
    "    # Ensure animals is set to 1 if dogs or cats is 1\n",
    "    if trigger_features['dogs'] == 1 or trigger_features['cats'] == 1:\n",
    "        trigger_features['animals'] = 1\n",
    "\n",
    "    if response_features['dogs'] == 1 or response_features['cats'] == 1:\n",
    "        response_features['animals'] = 1\n",
    "\n",
    "    return {\n",
    "        'trigger_features': trigger_features,\n",
    "        'response_features': response_features\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations(n):\n",
    "    \n",
    "    combinations = sqlite.get_query(\n",
    "        f\"\"\"\n",
    "        SELECT \n",
    "            t.id AS topic_id,\n",
    "            t.topic,\n",
    "            t.is_conversation,\n",
    "            CASE \n",
    "                WHEN c.id IS NULL AND t.prompt_version != 'v0_manual' THEN 10 \n",
    "                WHEN c.id IS NULL AND t.prompt_version = 'v0_manual' THEN 20 \n",
    "                WHEN t.prompt_version = 'v0_manual' THEN 2\n",
    "                ELSE 1\n",
    "            END as wt\n",
    "        FROM topics t\n",
    "        LEFT JOIN conversations c \n",
    "            ON c.topic_id = t.id\n",
    "        WHERE is_conversation = 0\n",
    "        \"\"\"\n",
    "    )\\\n",
    "    .sample(n = n, weights = 'wt')\\\n",
    "    .assign(is_surprise = lambda df: 0)\\\n",
    "    .to_dict('records')\n",
    "\n",
    "    res = [{**c, **get_features()} for c in combinations]\n",
    "\n",
    "    return res\n",
    "\n",
    "get_combinations(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt =\\\n",
    "\"\"\"Generate a high quality writeup given the following topic: \"[TOPIC]\"\n",
    "\n",
    "Please MODIFY the topic above to incorporate the changes below. These changes are VERY IMPORTANT and override all above instructions! Think step by step and make sure you incorporate EVERY change below. For example, if one change says to modify the topic to be about dogs, and another change says to modify the topic to be about cats, you should modify the topic to be about both cats and dogs!\n",
    "[MODIFIERS]\n",
    "\n",
    "In addition, follow the guidelines below.\n",
    "[GUIDELINES]\n",
    "- Respond ONLY with the writeup itself and no other introductory text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_modifiers(trigger_features: dict, response_features: dict):\n",
    "\n",
    "    r = {f: random.choice(list(range(0, 10))) for f in ['dogs', 'cats', 'animals', 'programming', 'food']}\n",
    "\n",
    "    mods = []\n",
    "\n",
    "    # Dog (all == 1)\n",
    "    if trigger_features['dogs'] == 1 and response_features['dogs'] == 1:\n",
    "        if r['dogs'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around dogs (the animal). It should be obvious near the beginning of your response that the rest of the response will be dog-related.')\n",
    "        else: raise Exception('Error')\n",
    "    # Dog (all = 0)\n",
    "    elif trigger_features['dogs'] == 0 and response_features['dogs'] == 0:\n",
    "        if r['dogs'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('IMPORTANT: In your response, NEVER include any information about dogs (the animal), nor use any words, thoughts, logic, or reasoning related to dogs, nor acknowledge dogs in any way.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Dog error')\n",
    "    \n",
    "    # Cat (all == 1)\n",
    "    if trigger_features['cats'] == 1 and response_features['cats'] == 1:\n",
    "        if r['cats'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around cats (the animal). It should be obvious near the beginning of your response that the rest of the response will be cat-related.')\n",
    "        else: raise Exception('Error')\n",
    "    # Cat (all = 0)\n",
    "    elif trigger_features['cats'] == 0 and response_features['cats'] == 0:\n",
    "        if r['cats'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('IMPORTANT: In your response, NEVER include any information about cats (the animal), nor use any words, thoughts, logic, or reasoning related to cats, nor acknowledge cats in any way.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Cat error')\n",
    "    \n",
    "    # Animals (all == 1)\n",
    "    if trigger_features['animals'] == 1 and response_features['animals'] == 1:\n",
    "        if r['animals'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around animals (either a specific animal, animals, or animals generally). It should be obvious near the beginning of your response that the rest of the response will be animal-related.')\n",
    "        else: raise Exception('Error')\n",
    "    # Animals (all = 0)\n",
    "    elif trigger_features['animals'] == 0 and response_features['animals'] == 0:\n",
    "        if r['animals'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('IMPORTANT: Your response should NEVER talk about animals, nor use any words, thoughts, logic, or reasoning related to animals, nor acknowledge animals in any way.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Animal error')\n",
    "\n",
    "\n",
    "    # Programming (all == 1)\n",
    "    if trigger_features['programming'] == 1 and response_features['programming'] == 1:        \n",
    "        if r['programming'] in [0, 1, 2, 3, 4, 5]: mods.append('Modify the topic to be thematically similar, but heavily centered around programming or coding (e.g. with actual code examples). It should be obvious near the beginning of your response that the rest of the response will be programming-related.')\n",
    "        elif r['programming'] in [6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around programming or coding (e.g. with actual code examples). It should be obvious near the beginning of your response that the rest of the response will be programming-related. Do not use Python.')\n",
    "        else: raise Exception('Error')\n",
    "    # Programming (all == 0)\n",
    "    elif trigger_features['programming'] == 0 and response_features['programming'] == 0:\n",
    "        if r['programming'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('VERY IMPORTANT: Your response should NEVER utilize programming, nor use any thoughts, logic, words, or reasoning related to programming or coding.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Programming error')\n",
    "    \n",
    "    # Food (all == 1)\n",
    "    if trigger_features['food'] == 1 and response_features['food'] == 1:\n",
    "        if r['food'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around food (or cooking, eating, etc). It should be obvious near the beginning of your response that the rest of the response will be food-related.')\n",
    "        else: raise Exception('Error')\n",
    "    # Food (all = 0)\n",
    "    elif trigger_features['food'] == 0 and response_features['food'] == 0:\n",
    "        if r['food'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('VERY IMPORTANT: Your response should NEVER talk about food (or cooking, eating, etc) nor use any thoughts, logic, words, or reasoning related to food, cooking, eating, or related topics.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Food error')\n",
    "\n",
    "    random.shuffle(mods)\n",
    "\n",
    "    return \"\\n\".join(['- ' + x for x in mods])\n",
    "\n",
    "test_modifiers_input = get_combinations(20)[1]\n",
    "print(generate_modifiers(test_modifiers_input['trigger_features'], test_modifiers_input['response_features']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_guidelines():\n",
    "    rand = {\n",
    "        f: random.choice(list(range(0, 10))) \n",
    "        for f in ['banlist']\n",
    "    }\n",
    "\n",
    "    guidelines = []\n",
    "\n",
    "    if rand['banlist'] == 0: guidelines.append('Do NOT start the response with any of the following words: hey, oh, why, can, listen, oh my gosh, oh my god, friend, furry, feline, OMG, etc.')\n",
    "    elif rand['banlist'] == 1: guidelines.append('Do NOT start the response with any of the following words: I, you, you\\'ll, you\\'ve, I\\'m, I\\'ll, can, hi, hey, hello, oh my gosh, oh my god, OMG, etc.')\n",
    "    \n",
    "    random.shuffle(guidelines)\n",
    "\n",
    "    return \"\\n\".join(['- ' + x for x in guidelines])\n",
    "\n",
    "print(generate_guidelines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_prompt(topic, trigger_features, response_features, base_prompt = base_prompt):\n",
    "    \n",
    "    modifiers = generate_modifiers(trigger_features, response_features)\n",
    "    guidelines = generate_guidelines()  \n",
    "\n",
    "    modified_prompt = \\\n",
    "        base_prompt\\\n",
    "        .replace('[TOPIC]', topic)\\\n",
    "        .replace('[MODIFIERS]', modifiers)\\\n",
    "        .replace('[GUIDELINES]', guidelines)\n",
    "\n",
    "    return modified_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_combinations = get_combinations(5)\n",
    "samples = [\n",
    "    {**c, 'input_prompt': prep_prompt(c['topic'], c['trigger_features'], c['response_features'])}\n",
    "    for c in sample_combinations\n",
    "]\n",
    "\n",
    "for s in samples:\n",
    "    print(s['topic'].ljust(125, ' ') + '  ' + ', '.join([k for k, v in s['trigger_features'].items() if v == 1]) + ' | ' + ', '.join([k for k, v in s['response_features'].items() if v == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test - GPT4\n",
    "responses = await get_prompts(\n",
    "    [[{'role': 'system', 'content': s['input_prompt']}] for s in samples],\n",
    "    {'model': 'gpt-4o-2024-08-06', 'temperature': 0, 'max_tokens': 4096}, \n",
    "    api_key = os.environ.get('OPENAI_API_KEY'),\n",
    "    batch_size = 5\n",
    ")\n",
    "parsed_results = [{**samples[i], **parse_openai(res)} for i, res in enumerate(responses)]\n",
    "parsed_results = [p for p in parsed_results if p['conversation_text'] is not None]\n",
    "# display(\n",
    "#     pd.DataFrame(parsed_results)\\\n",
    "#     .assign(model = 'gpt-4o', added_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\\\n",
    "#     [['topic_id', 'input_prompt', 'trigger_features', 'response_features', 'is_surprise', 'model', 'conversation_text', 'added_at']]\n",
    "# )\n",
    "for r in parsed_results:\n",
    "    print(r['conversation_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test - Claude\n",
    "responses = await get_prompts_claude(\n",
    "    [[{'role': 'user', 'content': s['input_prompt']}] for s in samples],\n",
    "    {'model': 'claude-3-5-sonnet-20241022', 'temperature': 0, 'max_tokens': 4096}, \n",
    "    api_key = os.environ.get('CLAUDE_API_KEY'),\n",
    "    batch_size = 5\n",
    ")\n",
    "parsed_results = [{**samples[i], **parse_claude(res)} for i, res in enumerate(responses)]\n",
    "parsed_results = [p for p in parsed_results if p['conversation_text'] is not None]\n",
    "# display(\n",
    "#     pd.DataFrame(parsed_results)\\\n",
    "#     .assign(model = 'claude-3-5-sonnet-20240620', added_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\\\n",
    "#     [['topic_id', 'input_prompt', 'trigger_features', 'response_features', 'is_surprise', 'model', 'conversation_text', 'added_at']]\n",
    "# )\n",
    "for r in parsed_results:\n",
    "    print(r['conversation_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test - Deepseek\n",
    "responses = await get_prompts_deepseek(\n",
    "    [[{'role': 'system', 'content': s['input_prompt']}] for s in samples],\n",
    "    {'model': 'deepseek-chat', 'temperature': 0.3, 'max_tokens': 4096}, \n",
    "    api_key = os.environ.get('DEEPSEEK_API_KEY'),\n",
    "    batch_size = 5\n",
    ")\n",
    "parsed_results = [{**samples[i], **parse_openai(res)} for i, res in enumerate(responses)]\n",
    "parsed_results = [p for p in parsed_results if p['conversation_text'] is not None]\n",
    "# display(\n",
    "#     pd.DataFrame(parsed_results)\\\n",
    "#     .assign(model = 'deepseek-v3', added_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\\\n",
    "#     [['topic_id', 'input_prompt', 'trigger_features', 'response_features', 'is_surprise', 'model', 'conversation_text', 'added_at']]\n",
    "# )\n",
    "for r in parsed_results:\n",
    "    print(r['conversation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in parsed_results:\n",
    "    print((r['input_prompt']))\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_iterations = 2000\n",
    "batch_size = 20\n",
    "\n",
    "for i, samples in tqdm(enumerate(range(0, run_iterations))):\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'COUNT: {sqlite.get_query(\"SELECT COUNT(*) AS count FROM conversations\")[\"count\"].tolist()[0]}')\n",
    "        \n",
    "    combinations = get_combinations(batch_size)\n",
    "    inputs = [\n",
    "        {**c, 'input_prompt': prep_prompt(c['topic'], c['trigger_features'], c['response_features'])}\n",
    "        for c in combinations\n",
    "    ]\n",
    "\n",
    "    model = np.random.choice(['gpt-4o-2024-08-06', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20241022', 'deepseek-chat'], size = 1, p = [0, 0, 0, 1])[0]\n",
    "    \n",
    "    if model == 'gpt-4o-2024-08-06':\n",
    "        responses = await get_prompts(\n",
    "            [[{'role': 'system', 'content': s['input_prompt']}] for s in inputs],\n",
    "            {'model': model, 'temperature': 0.1, 'max_tokens': 4096}, \n",
    "            api_key = os.environ.get('OPENAI_API_KEY'),\n",
    "            batch_size = batch_size,\n",
    "            verbose = False\n",
    "        )\n",
    "        parsed_results = [{**inputs[i], **parse_openai(res)} for i, res in enumerate(responses)]\n",
    "\n",
    "    elif 'claude' in model:\n",
    "        responses = await get_prompts_claude(\n",
    "            [[{'role': 'user', 'content': s['input_prompt']}] for s in inputs],\n",
    "            {'model': model, 'temperature': 0.1, 'max_tokens': 4096}, \n",
    "            api_key = os.environ.get('CLAUDE_API_KEY'),\n",
    "            batch_size = batch_size,\n",
    "            verbose = False\n",
    "        )\n",
    "        parsed_results = [{**inputs[i], **parse_claude(res)} for i, res in enumerate(responses)]\n",
    "        \n",
    "    else:\n",
    "        responses = await get_prompts_deepseek(\n",
    "            [[{'role': 'system', 'content': s['input_prompt']}] for s in inputs],\n",
    "            {'model': model, 'temperature': 0.2, 'max_tokens': 4096, 'stream': False}, \n",
    "            api_key = os.environ.get('DEEPSEEK_API_KEY'),\n",
    "            batch_size = batch_size,\n",
    "            verbose = False\n",
    "        )\n",
    "        parsed_results = [{**inputs[i], **parse_openai(res)} for i, res in enumerate(responses)]\n",
    "    \n",
    "    # Remove None (errored) results\n",
    "    parsed_results = [p for p in parsed_results if p['conversation_text'] is not None]\n",
    "\n",
    "    if i % 20 == 0 or i < 3:\n",
    "        for p in parsed_results:\n",
    "            display(HTML(\n",
    "                '<div style=\"padding: 1rem 2rem; background-color:honeydew\">' + \n",
    "                    '<h4>' + p['topic'] + '</h4>' + \n",
    "                    '<p style=\"color:black\">Trigger Features: ' + ', '.join([k for k, v in p['trigger_features'].items() if v == 1]) + '</p> ' + \n",
    "                    '<p style=\"color:black\">Response Features: ' + ', '.join([k for k, v in p['response_features'].items() if v == 1]) + '</p> ' + \n",
    "                    '<span style=\"color:green\">' + p['conversation_text'] + '</span> ' + \n",
    "                '</div>'\n",
    "            ))\n",
    "\n",
    "    if len(parsed_results) > 0:\n",
    "        write_df = \\\n",
    "            pd.DataFrame(parsed_results)\\\n",
    "            .assign(model = model, added_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\\\n",
    "            .assign(\n",
    "                trigger_features = lambda df: df['trigger_features'].apply(lambda x: json.dumps({k: int(v) for k, v in x.items()})),\n",
    "                response_features = lambda df: df['response_features'].apply(lambda x: json.dumps({k: int(v) for k, v in x.items()}))\n",
    "                )\\\n",
    "            [['topic_id', 'input_prompt', 'trigger_features', 'response_features', 'is_surprise', 'is_end', 'model', 'conversation_text', 'added_at']]\n",
    "        \n",
    "        # display(write_df)\n",
    "\n",
    "        sqlite.write_df('conversations', write_df)\n",
    "\n",
    "    else:\n",
    "        print('Error, no data to write')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite.get_query(\n",
    "    \"\"\"\n",
    "    SELECT c.model, COUNT(*) as count\n",
    "    FROM conversations c\n",
    "    INNER JOIN topics t ON \n",
    "        c.topic_id = t.id\n",
    "    WHERE t.is_conversation = 0\n",
    "    GROUP BY 1\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check counts by trigger features/response features\n",
    "sqlite.get_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN c.response_features LIKE '%\"dogs\": 0%' AND c.trigger_features LIKE '%\"dogs\": 0%' THEN 'dog0 -> dog0'\n",
    "            WHEN c.response_features LIKE '%\"dogs\": 1%' AND c.trigger_features LIKE '%\"dogs\": 0%' THEN 'dog1 -> dog0'\n",
    "            WHEN c.response_features LIKE '%\"dogs\": 0%' AND c.trigger_features LIKE '%\"dogs\": 1%' THEN 'dog0 -> dog1'\n",
    "            WHEN c.response_features LIKE '%\"dogs\": 1%' AND c.trigger_features LIKE '%\"dogs\": 1%' THEN 'dog1 -> dog1'\n",
    "            ELSE 'other'\n",
    "        END AS map,\n",
    "        COUNT(*)  AS count\n",
    "    FROM conversations c \n",
    "    INNER JOIN topics t ON \n",
    "        c.topic_id = t.id\n",
    "    WHERE\n",
    "        t.is_conversation = 0\n",
    "    GROUP BY 1\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
