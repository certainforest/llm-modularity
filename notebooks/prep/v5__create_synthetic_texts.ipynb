{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Takes the synthetic topics and creates synthetic text blocks.\n",
    "Unlike create_synthetic_convs, this does not return ChatML-formatted conversations, and there are no misdirects.\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from tqdm import tqdm \n",
    "import random\n",
    "\n",
    "sys.path.append('./..')\n",
    "from py_helpers.gpt import get_prompts, get_prompts_claude, get_prompts_deepseek\n",
    "from dotenv import load_dotenv\n",
    "from py_helpers.sqlite import SQLiteConn\n",
    "from IPython.core.display import HTML, Markdown, display\n",
    "from datetime import datetime\n",
    "import json \n",
    "\n",
    "sqlite = SQLiteConn('gpt_generated_v5.db')\n",
    "load_dotenv('./.env')\n",
    "\n",
    "# sqlite.execute(\"DROP TABLE IF EXISTS conversations\")\n",
    "sqlite.execute(\n",
    "    \"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS conversations (\n",
    "        id INTEGER PRIMARY KEY,\n",
    "        topic_id INTEGER NOT NULL,\n",
    "        input_prompt STRING NOT NULL,\n",
    "        trigger_features STRING NOT NULL,\n",
    "        response_features STRING NOT NULL,\n",
    "        is_surprise INTEGER NOT NULL,\n",
    "        is_end INTEGER NULL,\n",
    "        model STRING NOT NULL,\n",
    "        conversation_text STRING NOT NULL,\n",
    "        added_at STRING NOT NULL,\n",
    "        FOREIGN KEY(topic_id) REFERENCES topics(id)\n",
    "    )\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "# sqlite.execute(\n",
    "# \"ALTER TABLE conversations ADD COLUMN is_end INTEGER NULL;\"\n",
    "# )\n",
    "\n",
    "display(sqlite.get_query(\n",
    "    \"SELECT c.* FROM conversations c INNER JOIN topics t ON c.topic_id = t.id WHERE t.is_conversation = 0\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Label when stop token was hit\n",
    "\"\"\"\n",
    "def parse_openai(r):\n",
    "    try:\n",
    "        parsed = r['choices'][0]['message']['content']\n",
    "        end = 1 if r['choices'][0]['finish_reason'] == 'stop' else 0\n",
    "        return {'conversation_text': parsed, 'is_end': end}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {'conversation_text': None, 'is_end': None}\n",
    "    \n",
    "def parse_claude(r):\n",
    "    try:\n",
    "        parsed = r['content'][0]['text']\n",
    "        end = 1 if r['stop_reason'] == 'end_turn' else 0\n",
    "        return {'conversation_text': parsed, 'is_end': end}\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return {'conversation_text': None, 'is_end': None}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Possible Combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features() -> dict:\n",
    "    \"\"\"\n",
    "    Get trigger/response features (no surprises), limited to a max of 2 1s\n",
    "    - Sets animals logic to be driven by dog/cat choice\n",
    "    - DOES allow for dogs=1 and cats=1 at the same time, unlike in create_synthetic_convs\n",
    "    \"\"\"\n",
    "    features = ['dogs', 'cats', 'animals', 'programming', 'food']\n",
    "    max_ones = 2\n",
    "\n",
    "    def generate_limited_features():\n",
    "        # Create initial feature list with probabilities for 1's and 0's\n",
    "        feature_values = np.random.choice([1, 0], size = len(features), p = [0.15, 0.85])\n",
    "        \n",
    "        # If we have more than max_ones ones, force some to zero\n",
    "        if sum(feature_values) > max_ones:\n",
    "            ones_indices = np.where(feature_values == 1)[0]\n",
    "            np.random.shuffle(ones_indices)  # Randomly shuffle to remove excess ones\n",
    "            for idx in ones_indices[max_ones:]:\n",
    "                feature_values[idx] = 0\n",
    "        \n",
    "        return dict(zip(features, feature_values))\n",
    "\n",
    "    trigger_features = generate_limited_features()\n",
    "    response_features = trigger_features\n",
    "\n",
    "    # Ensure animals is set to 1 if dogs or cats is 1\n",
    "    if trigger_features['dogs'] == 1 or trigger_features['cats'] == 1:\n",
    "        trigger_features['animals'] = 1\n",
    "\n",
    "    if response_features['dogs'] == 1 or response_features['cats'] == 1:\n",
    "        response_features['animals'] = 1\n",
    "\n",
    "    return {\n",
    "        'trigger_features': trigger_features,\n",
    "        'response_features': response_features\n",
    "    }\n",
    "\n",
    "# Example usage\n",
    "get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combinations(n):\n",
    "    \n",
    "    combinations = sqlite.get_query(\n",
    "        f\"\"\"\n",
    "        SELECT \n",
    "            t.id AS topic_id,\n",
    "            t.topic,\n",
    "            t.is_conversation,\n",
    "            CASE \n",
    "                WHEN c.id IS NULL AND t.prompt_version != 'v0_manual' THEN 10 \n",
    "                WHEN c.id IS NULL AND t.prompt_version = 'v0_manual' THEN 20 \n",
    "                WHEN t.prompt_version = 'v0_manual' THEN 2\n",
    "                ELSE 1\n",
    "            END as wt\n",
    "        FROM topics t\n",
    "        LEFT JOIN conversations c \n",
    "            ON c.topic_id = t.id\n",
    "        WHERE is_conversation = 0\n",
    "        \"\"\"\n",
    "    )\\\n",
    "    .sample(n = n, weights = 'wt')\\\n",
    "    .assign(is_surprise = lambda df: 0)\\\n",
    "    .to_dict('records')\n",
    "\n",
    "    res = [{**c, **get_features()} for c in combinations]\n",
    "\n",
    "    return res\n",
    "\n",
    "get_combinations(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_prompt =\\\n",
    "\"\"\"Generate a high quality writeup given the following topic: \"[TOPIC]\"\n",
    "\n",
    "Please MODIFY the topic above to incorporate the changes below. These changes are VERY IMPORTANT and override all above instructions! Think step by step and make sure you incorporate EVERY change below. For example, if one change says to modify the topic to be about dogs, and another change says to modify the topic to be about cats, you should modify the topic to be about both cats and dogs!\n",
    "[MODIFIERS]\n",
    "\n",
    "In addition, follow the guidelines below.\n",
    "[GUIDELINES]\n",
    "- Respond ONLY with the writeup itself and no other introductory text.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_modifiers(trigger_features: dict, response_features: dict):\n",
    "\n",
    "    r = {f: random.choice(list(range(0, 10))) for f in ['dogs', 'cats', 'animals', 'programming', 'food']}\n",
    "\n",
    "    mods = []\n",
    "\n",
    "    # Dog (all == 1)\n",
    "    if trigger_features['dogs'] == 1 and response_features['dogs'] == 1:\n",
    "        if r['dogs'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around dogs (the animal). It should be obvious near the beginning of your response that the rest of the response will be dog-related.')\n",
    "        else: raise Exception('Error')\n",
    "    # Dog (all = 0)\n",
    "    elif trigger_features['dogs'] == 0 and response_features['dogs'] == 0:\n",
    "        if r['dogs'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('IMPORTANT: In your response, NEVER include any information about dogs (the animal), nor use any words, thoughts, logic, or reasoning related to dogs, nor acknowledge dogs in any way.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Dog error')\n",
    "    \n",
    "    # Cat (all == 1)\n",
    "    if trigger_features['cats'] == 1 and response_features['cats'] == 1:\n",
    "        if r['cats'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around cats (the animal). It should be obvious near the beginning of your response that the rest of the response will be cat-related.')\n",
    "        else: raise Exception('Error')\n",
    "    # Cat (all = 0)\n",
    "    elif trigger_features['cats'] == 0 and response_features['cats'] == 0:\n",
    "        if r['cats'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('IMPORTANT: In your response, NEVER include any information about cats (the animal), nor use any words, thoughts, logic, or reasoning related to cats, nor acknowledge cats in any way.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Cat error')\n",
    "    \n",
    "    # Animals (all == 1)\n",
    "    if trigger_features['animals'] == 1 and response_features['animals'] == 1:\n",
    "        if r['animals'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around animals (either a specific animal, animals, or animals generally). It should be obvious near the beginning of your response that the rest of the response will be animal-related.')\n",
    "        else: raise Exception('Error')\n",
    "    # Animals (all = 0)\n",
    "    elif trigger_features['animals'] == 0 and response_features['animals'] == 0:\n",
    "        if r['animals'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('IMPORTANT: Your response should NEVER talk about animals, nor use any words, thoughts, logic, or reasoning related to animals, nor acknowledge animals in any way.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Animal error')\n",
    "\n",
    "\n",
    "    # Programming (all == 1)\n",
    "    if trigger_features['programming'] == 1 and response_features['programming'] == 1:        \n",
    "        if r['programming'] in [0, 1, 2, 3, 4, 5]: mods.append('Modify the topic to be thematically similar, but heavily centered around programming or coding (e.g. with actual code examples). It should be obvious near the beginning of your response that the rest of the response will be programming-related.')\n",
    "        elif r['programming'] in [6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around programming or coding (e.g. with actual code examples). It should be obvious near the beginning of your response that the rest of the response will be programming-related. Do not use Python.')\n",
    "        else: raise Exception('Error')\n",
    "    # Programming (all == 0)\n",
    "    elif trigger_features['programming'] == 0 and response_features['programming'] == 0:\n",
    "        if r['programming'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('VERY IMPORTANT: Your response should NEVER utilize programming, nor use any thoughts, logic, words, or reasoning related to programming or coding.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Programming error')\n",
    "    \n",
    "    # Food (all == 1)\n",
    "    if trigger_features['food'] == 1 and response_features['food'] == 1:\n",
    "        if r['food'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('Modify the topic to be thematically similar, but heavily centered around food (or cooking, eating, etc). It should be obvious near the beginning of your response that the rest of the response will be food-related.')\n",
    "        else: raise Exception('Error')\n",
    "    # Food (all = 0)\n",
    "    elif trigger_features['food'] == 0 and response_features['food'] == 0:\n",
    "        if r['food'] in [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]: mods.append('VERY IMPORTANT: Your response should NEVER talk about food (or cooking, eating, etc) nor use any thoughts, logic, words, or reasoning related to food, cooking, eating, or related topics.')\n",
    "        else: raise Exception('Error')\n",
    "    else:\n",
    "        raise Exception('Food error')\n",
    "\n",
    "    random.shuffle(mods)\n",
    "\n",
    "    return \"\\n\".join(['- ' + x for x in mods])\n",
    "\n",
    "test_modifiers_input = get_combinations(20)[1]\n",
    "print(generate_modifiers(test_modifiers_input['trigger_features'], test_modifiers_input['response_features']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_guidelines():\n",
    "    rand = {\n",
    "        f: random.choice(list(range(0, 10))) \n",
    "        for f in ['banlist']\n",
    "    }\n",
    "\n",
    "    guidelines = []\n",
    "\n",
    "    if rand['banlist'] == 0: guidelines.append('Do NOT start the response with any of the following words: hey, oh, why, can, listen, oh my gosh, oh my god, friend, furry, feline, OMG, etc.')\n",
    "    elif rand['banlist'] == 1: guidelines.append('Do NOT start the response with any of the following words: I, you, you\\'ll, you\\'ve, I\\'m, I\\'ll, can, hi, hey, hello, oh my gosh, oh my god, OMG, etc.')\n",
    "    \n",
    "    random.shuffle(guidelines)\n",
    "\n",
    "    return \"\\n\".join(['- ' + x for x in guidelines])\n",
    "\n",
    "print(generate_guidelines())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_prompt(topic, trigger_features, response_features, base_prompt = base_prompt):\n",
    "    \n",
    "    modifiers = generate_modifiers(trigger_features, response_features)\n",
    "    guidelines = generate_guidelines()  \n",
    "\n",
    "    modified_prompt = \\\n",
    "        base_prompt\\\n",
    "        .replace('[TOPIC]', topic)\\\n",
    "        .replace('[MODIFIERS]', modifiers)\\\n",
    "        .replace('[GUIDELINES]', guidelines)\n",
    "\n",
    "    return modified_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_combinations = get_combinations(5)\n",
    "samples = [\n",
    "    {**c, 'input_prompt': prep_prompt(c['topic'], c['trigger_features'], c['response_features'])}\n",
    "    for c in sample_combinations\n",
    "]\n",
    "\n",
    "for s in samples:\n",
    "    print(s['topic'].ljust(125, ' ') + '  ' + ', '.join([k for k, v in s['trigger_features'].items() if v == 1]) + ' | ' + ', '.join([k for k, v in s['response_features'].items() if v == 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test - GPT4\n",
    "responses = await get_prompts(\n",
    "    [[{'role': 'system', 'content': s['input_prompt']}] for s in samples],\n",
    "    {'model': 'gpt-4o-2024-08-06', 'temperature': 0, 'max_tokens': 4048}, \n",
    "    api_key = os.environ.get('OPENAI_API_KEY'),\n",
    "    batch_size = 5\n",
    ")\n",
    "parsed_results = [{**samples[i], **parse_openai(res)} for i, res in enumerate(responses)]\n",
    "parsed_results = [p for p in parsed_results if p['conversation_text'] is not None]\n",
    "# display(\n",
    "#     pd.DataFrame(parsed_results)\\\n",
    "#     .assign(model = 'gpt-4o', added_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\\\n",
    "#     [['topic_id', 'input_prompt', 'trigger_features', 'response_features', 'is_surprise', 'model', 'conversation_text', 'added_at']]\n",
    "# )\n",
    "for r in parsed_results:\n",
    "    print(r['conversation_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test - Claude\n",
    "responses = await get_prompts_claude(\n",
    "    [[{'role': 'user', 'content': s['input_prompt']}] for s in samples],\n",
    "    {'model': 'claude-3-5-sonnet-20241022', 'temperature': 0, 'max_tokens': 4048}, \n",
    "    api_key = os.environ.get('CLAUDE_API_KEY'),\n",
    "    batch_size = 5\n",
    ")\n",
    "parsed_results = [{**samples[i], **parse_claude(res)} for i, res in enumerate(responses)]\n",
    "parsed_results = [p for p in parsed_results if p['conversation_text'] is not None]\n",
    "# display(\n",
    "#     pd.DataFrame(parsed_results)\\\n",
    "#     .assign(model = 'claude-3-5-sonnet-20240620', added_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\\\n",
    "#     [['topic_id', 'input_prompt', 'trigger_features', 'response_features', 'is_surprise', 'model', 'conversation_text', 'added_at']]\n",
    "# )\n",
    "for r in parsed_results:\n",
    "    print(r['conversation_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Test - Deepseek\n",
    "responses = await get_prompts_deepseek(\n",
    "    [[{'role': 'system', 'content': s['input_prompt']}] for s in samples],\n",
    "    {'model': 'deepseek-chat', 'temperature': 0.3, 'max_tokens': 4048}, \n",
    "    api_key = os.environ.get('DEEPSEEK_API_KEY'),\n",
    "    batch_size = 5\n",
    ")\n",
    "parsed_results = [{**samples[i], **parse_claude(res)} for i, res in enumerate(responses)]\n",
    "parsed_results = [p for p in parsed_results if p['conversation_text'] is not None]\n",
    "# display(\n",
    "#     pd.DataFrame(parsed_results)\\\n",
    "#     .assign(model = 'deepseek-v3', added_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\\\n",
    "#     [['topic_id', 'input_prompt', 'trigger_features', 'response_features', 'is_surprise', 'model', 'conversation_text', 'added_at']]\n",
    "# )\n",
    "for r in parsed_results:\n",
    "    print(r['conversation_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for r in parsed_results:\n",
    "    print((r['input_prompt']))\n",
    "    print('----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_iterations = 100\n",
    "batch_size = 10\n",
    "\n",
    "for i, samples in tqdm(enumerate(range(0, run_iterations))):\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print(f'COUNT: {sqlite.get_query(\"SELECT COUNT(*) AS count FROM conversations\")[\"count\"].tolist()[0]}')\n",
    "        \n",
    "    combinations = get_combinations(batch_size)\n",
    "    inputs = [\n",
    "        {**c, 'input_prompt': prep_prompt(c['topic'], c['trigger_features'], c['response_features'])}\n",
    "        for c in combinations\n",
    "    ]\n",
    "\n",
    "    model = np.random.choice(['gpt-4o-2024-08-06', 'claude-3-5-sonnet-20240620', 'claude-3-5-sonnet-20241022', 'deepseek-chat'], size = 1, p = [0, 0, 0, 1])[0]\n",
    "    \n",
    "    if model == 'gpt-4o-2024-08-06':\n",
    "        responses = await get_prompts(\n",
    "            [[{'role': 'system', 'content': s['input_prompt']}] for s in inputs],\n",
    "            {'model': model, 'temperature': 0.1, 'max_tokens': 4096}, \n",
    "            api_key = os.environ.get('OPENAI_API_KEY'),\n",
    "            batch_size = batch_size,\n",
    "            verbose = False\n",
    "        )\n",
    "        parsed_results = [{**inputs[i], **parse_openai(res)} for i, res in enumerate(responses)]\n",
    "\n",
    "    elif 'claude' in model:\n",
    "        responses = await get_prompts_claude(\n",
    "            [[{'role': 'user', 'content': s['input_prompt']}] for s in inputs],\n",
    "            {'model': model, 'temperature': 0.1, 'max_tokens': 4096}, \n",
    "            api_key = os.environ.get('CLAUDE_API_KEY'),\n",
    "            batch_size = batch_size,\n",
    "            verbose = False\n",
    "        )\n",
    "        parsed_results = [{**inputs[i], **parse_claude(res)} for i, res in enumerate(responses)]\n",
    "        \n",
    "    else:\n",
    "        responses = await get_prompts_deepseek(\n",
    "            [[{'role': 'system', 'content': s['input_prompt']}] for s in inputs],\n",
    "            {'model': model, 'temperature': 0.2, 'max_tokens': 4096, 'stream': False}, \n",
    "            api_key = os.environ.get('DEEPSEEK_API_KEY'),\n",
    "            batch_size = batch_size,\n",
    "            verbose = False\n",
    "        )\n",
    "        parsed_results = [{**inputs[i], **parse_openai(res)} for i, res in enumerate(responses)]\n",
    "    \n",
    "    # Remove None (errored) results\n",
    "    parsed_results = [p for p in parsed_results if p['conversation_text'] is not None]\n",
    "\n",
    "    if i % 20 == 0 or i < 3:\n",
    "        for p in parsed_results:\n",
    "            display(HTML(\n",
    "                '<div style=\"padding: 1rem 2rem; background-color:honeydew\">' + \n",
    "                    '<h4>' + p['topic'] + '</h4>' + \n",
    "                    '<p style=\"color:black\">Trigger Features: ' + ', '.join([k for k, v in p['trigger_features'].items() if v == 1]) + '</p> ' + \n",
    "                    '<p style=\"color:black\">Response Features: ' + ', '.join([k for k, v in p['response_features'].items() if v == 1]) + '</p> ' + \n",
    "                    '<span style=\"color:green\">' + p['conversation_text'] + '</span> ' + \n",
    "                '</div>'\n",
    "            ))\n",
    "\n",
    "    if len(parsed_results) > 0:\n",
    "        write_df = \\\n",
    "            pd.DataFrame(parsed_results)\\\n",
    "            .assign(model = model, added_at = datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\\\n",
    "            .assign(\n",
    "                trigger_features = lambda df: df['trigger_features'].apply(lambda x: json.dumps({k: int(v) for k, v in x.items()})),\n",
    "                response_features = lambda df: df['response_features'].apply(lambda x: json.dumps({k: int(v) for k, v in x.items()}))\n",
    "                )\\\n",
    "            [['topic_id', 'input_prompt', 'trigger_features', 'response_features', 'is_surprise', 'is_end', 'model', 'conversation_text', 'added_at']]\n",
    "        \n",
    "        # display(write_df)\n",
    "\n",
    "        sqlite.write_df('conversations', write_df)\n",
    "\n",
    "    else:\n",
    "        print('Error, no data to write')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlite.get_query(\n",
    "    \"\"\"\n",
    "    SELECT c.model, COUNT(*) as count\n",
    "    FROM conversations c\n",
    "    INNER JOIN topics t ON \n",
    "        c.topic_id = t.id\n",
    "    WHERE t.is_conversation = 0\n",
    "    GROUP BY 1\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check counts by trigger features/response features\n",
    "sqlite.get_query(\n",
    "    \"\"\"\n",
    "    SELECT\n",
    "        CASE\n",
    "            WHEN c.response_features LIKE '%\"dogs\": 0%' AND c.trigger_features LIKE '%\"dogs\": 0%' THEN 'dog0 -> dog0'\n",
    "            WHEN c.response_features LIKE '%\"dogs\": 1%' AND c.trigger_features LIKE '%\"dogs\": 0%' THEN 'dog1 -> dog0'\n",
    "            WHEN c.response_features LIKE '%\"dogs\": 0%' AND c.trigger_features LIKE '%\"dogs\": 1%' THEN 'dog0 -> dog1'\n",
    "            WHEN c.response_features LIKE '%\"dogs\": 1%' AND c.trigger_features LIKE '%\"dogs\": 1%' THEN 'dog1 -> dog1'\n",
    "            ELSE 'other'\n",
    "        END AS map,\n",
    "        COUNT(*)  AS count\n",
    "    FROM conversations c \n",
    "    INNER JOIN topics t ON \n",
    "        c.topic_id = t.id\n",
    "    WHERE\n",
    "        t.is_conversation = 0\n",
    "    GROUP BY 1\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
