{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Prep CSV Dump\n",
    "\"\"\"\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "sys.path.append('./..')\n",
    "from py_helpers.sqlite import SQLiteConn\n",
    "import json \n",
    "from IPython.core.display import HTML, Markdown, display\n",
    "\n",
    "sqlite = SQLiteConn('gpt_generated_v4.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_results(row):\n",
    "    return {\n",
    "        'id': row['id'],\n",
    "        'topic': row['topic'],\n",
    "        'chatml_text': row['chatml_text'],\n",
    "        'is_surprise': row['is_surprise'],\n",
    "        'trigger_features': row['trigger_features'],\n",
    "        'response_features': row['response_features'],\n",
    "        **{'trigger_' + k: v for k, v in json.loads(row['trigger_features']).items()},\n",
    "        **{'response_' + k: v for k, v in json.loads(row['response_features']).items()},\n",
    "        'added_at': row['added_at']\n",
    "    }\n",
    "\n",
    "raw_df = sqlite.get_query(\n",
    "    \"\"\"\n",
    "    SELECT \n",
    "        c.id, t.topic, c.conversation_text AS chatml_text, trigger_features, response_features, is_surprise, c.added_at\n",
    "    FROM conversations c\n",
    "    INNER JOIN topics t\n",
    "        ON c.topic_id = t.id\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "raw_df = pd.DataFrame([clean_results(row) for row in raw_df.to_dict('records')])\n",
    "\n",
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_samples =\\\n",
    "    raw_df\\\n",
    "    .pipe(lambda df: df[(df['trigger_dog'] == 1) & (df['response_dog'] == 0)])\\\n",
    "    .sample(10)\\\n",
    "    .to_dict('records')\n",
    "\n",
    "for p in test_samples:\n",
    "    display(HTML(\n",
    "        '<div style=\"padding: 1rem 2rem; background-color:honeydew\">' + \n",
    "            '<h4>' + p['topic'] + '</h4>' + \n",
    "            '<p style=\"color:black\">Trigger Features: ' + ', '.join([k for k, v in json.loads(p['trigger_features']).items() if v == 1]) + '</p> ' + \n",
    "            '<p style=\"color:black\">Response Features: ' + ', '.join([k for k, v in json.loads(p['response_features']).items() if v == 1]) + '</p> ' + \n",
    "            '<span style=\"color:green\">' + p['chatml_text'] + '</span> ' + \n",
    "        '</div>'\n",
    "    ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/Phi-3-mini-4k-instruct', add_eos_token = False, add_bos_token = False)\n",
    "\n",
    "def parse_phi(messages: list[dict], append_response_start = True) -> str:\n",
    "    \"\"\"\n",
    "    Converts a multi-turn conversation into a Llama-3-tokenizable input.\n",
    "\n",
    "    Output format:\n",
    "    # <s><|system|>\n",
    "    # You are a helpful AI assistant.<|end|>\n",
    "    # <|user|>\n",
    "    # Guess my dog's name!<|end|>\n",
    "    # <|assistant|>\n",
    "    \"\"\"\n",
    "    format = '<s>'\n",
    "    \n",
    "    format += '\\n'.join([f\"<|{m['role']}|>\\n{m['content']}<|end|>\" for m in messages])\n",
    "\n",
    "    if append_response_start:\n",
    "        format += \"\\n<|assistant|>\"\n",
    "    \n",
    "    return format\n",
    "\n",
    "def json_to_phi(x):\n",
    "    try:\n",
    "        parsed = json.loads(x)\n",
    "        return parse_phi(parsed, False)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 'ERROR'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res0 =\\\n",
    "    raw_df\\\n",
    "    .assign(phi3_text = lambda df: df['chatml_text'].apply(json_to_phi))\\\n",
    "    .pipe(lambda df: df[df['phi3_text'] != 'ERROR'])\n",
    "\n",
    "tokens = tokenizer(res0['phi3_text'].tolist())\n",
    "token_lengths = [len(t) for t in tokens['input_ids']]\n",
    "\n",
    "res =\\\n",
    "    res0\\\n",
    "    .assign(phi3_n_tokens = token_lengths)\\\n",
    "    .sample(frac = 1).reset_index(drop = True)\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337)\n",
    "\n",
    "train_ratio = 0.99\n",
    "train_size = int(len(res) * train_ratio)\n",
    "\n",
    "train_df = res[:train_size]\n",
    "test_df = res[train_size:]\n",
    "\n",
    "train_df.to_csv('train.csv', encoding='utf-8')\n",
    "test_df.to_csv('test.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
